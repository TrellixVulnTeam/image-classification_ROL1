{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 1 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16922e80>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x=x/255\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "    lb.fit([0,1,2,3,4,5,6,7,8,9])\n",
    "    x=lb.transform(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = tf.placeholder(tf.float32,[None,image_shape[0],image_shape[1],image_shape[2]],name = 'x')\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    y = tf.placeholder(tf.float32,[None,n_classes],name = 'y')\n",
    "    return y\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob = tf.placeholder(tf.float32,name = 'keep_prob')\n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    padding = 'SAME'\n",
    "    depth = x_tensor.get_shape().as_list()\n",
    "    conv_ksize2 = [conv_ksize[0],conv_ksize[1],depth[-1],conv_num_outputs]\n",
    "    conv_strides2 = [1,conv_strides[0],conv_strides[1],1]\n",
    "    pool_ksize2 = [1,pool_ksize[0],pool_ksize[1],1]\n",
    "    pool_strides2 = [1,pool_strides[0],pool_strides[1],1]\n",
    "    conv2d_weights = tf.Variable(tf.truncated_normal((conv_ksize2),0,0.1))\n",
    "    conv2d_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    fifter_output = tf.nn.conv2d(x_tensor,conv2d_weights,conv_strides2,padding)\n",
    "    fifter_output = tf.nn.bias_add(fifter_output,conv2d_bias)\n",
    "    \n",
    "    fifter_output = tf.nn.relu(fifter_output)\n",
    "    \n",
    "    fifter_output = tf.nn.max_pool(fifter_output,pool_ksize2,pool_strides2,padding)\n",
    "    return fifter_output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flattened_image_size = np.prod(x_tensor.get_shape().as_list()[1:])\n",
    "    flatten_size = tf.reshape(x_tensor,[-1,flattened_image_size])\n",
    "    \n",
    "    return flatten_size\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用全连接层，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal((x_tensor.get_shape().as_list()[-1],num_outputs),0,0.1))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    output = tf.nn.relu(tf.add(tf.matmul(x_tensor, weights), bias))\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal((x_tensor.get_shape().as_list()[-1],num_outputs),0,0.1))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    output = tf.nn.relu(tf.add(tf.matmul(x_tensor, weights), bias))\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 32, 32, 3]\n",
      "[None, 16, 16, 18]\n",
      "[None, 8, 8, 64]\n",
      "[None, 4, 4, 64]\n",
      "WARNING:tensorflow:From <ipython-input-12-fe0a5a9beb1a>:73: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "[None, 32, 32, 3]\n",
      "[None, 16, 16, 18]\n",
      "[None, 8, 8, 64]\n",
      "[None, 4, 4, 64]\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print(x.get_shape().as_list())\n",
    "    output1 = conv2d_maxpool(x,18,(8,8),(1,1),(2,2),(2,2))\n",
    "    output1 = tf.nn.dropout(output1,keep_prob)\n",
    "    print(output1.get_shape().as_list())\n",
    "    output2 = conv2d_maxpool(output1,64,(5,5),(1,1),(2,2),(2,2))\n",
    "    output2 = tf.nn.dropout(output2,keep_prob)\n",
    "    print(output2.get_shape().as_list())\n",
    "    output3 = conv2d_maxpool(output2,64,(3,3),(1,1),(2,2),(2,2))\n",
    "    output3 = tf.nn.dropout(output3,keep_prob)\n",
    "    print(output3.get_shape().as_list())\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    output4 = flatten(output3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    output5 = fully_conn(output4,500)\n",
    "    output5 = tf.nn.dropout(output5,keep_prob)\n",
    "    \n",
    "    output6 = fully_conn(output5,100)\n",
    "    output6 = tf.nn.dropout(output6,keep_prob)\n",
    "    \n",
    "    output7 = fully_conn(output6,50)\n",
    "    output7 = tf.nn.dropout(output7,keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output8 = output(output7,10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output8\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,feed_dict = {x:feature_batch,y:label_batch,keep_prob:keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost,feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_accuracy = session.run(accuracy,feed_dict={x:valid_features, y:valid_labels, keep_prob:1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                loss,\n",
    "                valid_accuracy))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.098000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.098000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.098000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.098000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.3027 Validation Accuracy: 0.108600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.3022 Validation Accuracy: 0.123200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.3000 Validation Accuracy: 0.109200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.2967 Validation Accuracy: 0.108400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.2893 Validation Accuracy: 0.128600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.3026 Validation Accuracy: 0.097800\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.3026 Validation Accuracy: 0.098000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.103600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.2942 Validation Accuracy: 0.117200\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     2.2939 Validation Accuracy: 0.105000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     2.2890 Validation Accuracy: 0.100200\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     2.2995 Validation Accuracy: 0.113000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2923 Validation Accuracy: 0.155800\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.2778 Validation Accuracy: 0.143800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     2.2705 Validation Accuracy: 0.147800\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     2.2814 Validation Accuracy: 0.144400\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     2.2809 Validation Accuracy: 0.168800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.2372 Validation Accuracy: 0.197000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     2.2300 Validation Accuracy: 0.167200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     2.2389 Validation Accuracy: 0.168200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     2.2376 Validation Accuracy: 0.174200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     2.2235 Validation Accuracy: 0.162600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.1684 Validation Accuracy: 0.189200\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     2.1817 Validation Accuracy: 0.169800\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     2.2065 Validation Accuracy: 0.160000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     2.0515 Validation Accuracy: 0.186000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     2.1582 Validation Accuracy: 0.174000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.2318 Validation Accuracy: 0.208800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.9238 Validation Accuracy: 0.210800\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.9212 Validation Accuracy: 0.162400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.9177 Validation Accuracy: 0.209600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     2.2458 Validation Accuracy: 0.177000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.2640 Validation Accuracy: 0.207600\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.9752 Validation Accuracy: 0.217200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.9543 Validation Accuracy: 0.175400\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.8063 Validation Accuracy: 0.273000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     2.3608 Validation Accuracy: 0.169400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.2236 Validation Accuracy: 0.241200\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.9653 Validation Accuracy: 0.244600\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.8020 Validation Accuracy: 0.245400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.9138 Validation Accuracy: 0.216400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     2.3179 Validation Accuracy: 0.205800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.2208 Validation Accuracy: 0.264200\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.9245 Validation Accuracy: 0.253800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.8568 Validation Accuracy: 0.230400\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.8379 Validation Accuracy: 0.253800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     2.1068 Validation Accuracy: 0.239000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.9993 Validation Accuracy: 0.299600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.9314 Validation Accuracy: 0.270800\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.8677 Validation Accuracy: 0.258400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.8072 Validation Accuracy: 0.280200\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     2.0316 Validation Accuracy: 0.262600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.1980 Validation Accuracy: 0.273800\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.8903 Validation Accuracy: 0.282000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.8221 Validation Accuracy: 0.264800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.8529 Validation Accuracy: 0.262200\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     2.0125 Validation Accuracy: 0.276600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.9561 Validation Accuracy: 0.298600\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.9164 Validation Accuracy: 0.242200\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.8104 Validation Accuracy: 0.288000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.7254 Validation Accuracy: 0.298400\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     2.0667 Validation Accuracy: 0.284600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.8244 Validation Accuracy: 0.336400\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.8383 Validation Accuracy: 0.315600\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     2.0046 Validation Accuracy: 0.250800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.7353 Validation Accuracy: 0.301200\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     2.1346 Validation Accuracy: 0.278200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.8971 Validation Accuracy: 0.333000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.7999 Validation Accuracy: 0.301000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.7926 Validation Accuracy: 0.296000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.7272 Validation Accuracy: 0.324600\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     2.0808 Validation Accuracy: 0.292000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.8683 Validation Accuracy: 0.347600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.7218 Validation Accuracy: 0.342200\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.7292 Validation Accuracy: 0.333800\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.6674 Validation Accuracy: 0.338000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.8955 Validation Accuracy: 0.326600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.7270 Validation Accuracy: 0.378800\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.7565 Validation Accuracy: 0.347600\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.7935 Validation Accuracy: 0.319600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.6455 Validation Accuracy: 0.348600\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     2.0528 Validation Accuracy: 0.284400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.8759 Validation Accuracy: 0.344400\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.7444 Validation Accuracy: 0.327800\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.8768 Validation Accuracy: 0.311800\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.5858 Validation Accuracy: 0.385400\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.9036 Validation Accuracy: 0.339200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.8431 Validation Accuracy: 0.338000\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.7163 Validation Accuracy: 0.342000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.6409 Validation Accuracy: 0.369800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.6044 Validation Accuracy: 0.365600\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.8439 Validation Accuracy: 0.358600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.6564 Validation Accuracy: 0.397000\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.6637 Validation Accuracy: 0.356600\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.7565 Validation Accuracy: 0.365800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.6013 Validation Accuracy: 0.388800\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.9324 Validation Accuracy: 0.347000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.6351 Validation Accuracy: 0.392200\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.6107 Validation Accuracy: 0.386400\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.7100 Validation Accuracy: 0.374400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.5071 Validation Accuracy: 0.413000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.9187 Validation Accuracy: 0.344600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.6106 Validation Accuracy: 0.398000\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.6253 Validation Accuracy: 0.368400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.6544 Validation Accuracy: 0.398800\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.5109 Validation Accuracy: 0.403200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.8934 Validation Accuracy: 0.363400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.6840 Validation Accuracy: 0.369400\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.6090 Validation Accuracy: 0.402200\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.6018 Validation Accuracy: 0.386800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.4912 Validation Accuracy: 0.406200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.9136 Validation Accuracy: 0.352400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.6738 Validation Accuracy: 0.364400\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.5935 Validation Accuracy: 0.394600\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.6803 Validation Accuracy: 0.390400\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.5093 Validation Accuracy: 0.403600\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.8429 Validation Accuracy: 0.378200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.4894 Validation Accuracy: 0.415400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.5839 Validation Accuracy: 0.381200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.7690 Validation Accuracy: 0.372200\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.4420 Validation Accuracy: 0.416400\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.6660 Validation Accuracy: 0.429600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.5083 Validation Accuracy: 0.411400\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.6025 Validation Accuracy: 0.373600\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.7583 Validation Accuracy: 0.371200\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.5078 Validation Accuracy: 0.411200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.8456 Validation Accuracy: 0.391600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.6684 Validation Accuracy: 0.393800\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.5694 Validation Accuracy: 0.401400\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.5762 Validation Accuracy: 0.403200\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.4271 Validation Accuracy: 0.417000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.7959 Validation Accuracy: 0.388600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.5953 Validation Accuracy: 0.401600\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.5098 Validation Accuracy: 0.441000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.7294 Validation Accuracy: 0.390400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.3909 Validation Accuracy: 0.419200\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.7402 Validation Accuracy: 0.411000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.4845 Validation Accuracy: 0.436000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.4930 Validation Accuracy: 0.419600\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.5478 Validation Accuracy: 0.417600\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.3692 Validation Accuracy: 0.438400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.7475 Validation Accuracy: 0.393200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.4799 Validation Accuracy: 0.439800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.5339 Validation Accuracy: 0.425600\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.5541 Validation Accuracy: 0.417200\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.3590 Validation Accuracy: 0.452800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.6307 Validation Accuracy: 0.433400\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.3972 Validation Accuracy: 0.454600\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.5359 Validation Accuracy: 0.433800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.4824 Validation Accuracy: 0.447800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.3970 Validation Accuracy: 0.449200\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.6678 Validation Accuracy: 0.431200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.4811 Validation Accuracy: 0.448400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.4195 Validation Accuracy: 0.461400\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.5292 Validation Accuracy: 0.391600\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.3893 Validation Accuracy: 0.436000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.7042 Validation Accuracy: 0.422800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.4032 Validation Accuracy: 0.444800\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.3498 Validation Accuracy: 0.464600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.5234 Validation Accuracy: 0.444600\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.3643 Validation Accuracy: 0.445200\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.5309 Validation Accuracy: 0.449200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.3718 Validation Accuracy: 0.460600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.4623 Validation Accuracy: 0.433800\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.5393 Validation Accuracy: 0.458400\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.3558 Validation Accuracy: 0.433600\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.5782 Validation Accuracy: 0.446000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.3685 Validation Accuracy: 0.462400\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.3643 Validation Accuracy: 0.491800\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.4041 Validation Accuracy: 0.478600\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.3771 Validation Accuracy: 0.453200\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.7939 Validation Accuracy: 0.408800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.4723 Validation Accuracy: 0.437000\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.3927 Validation Accuracy: 0.463400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.5162 Validation Accuracy: 0.450400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.3030 Validation Accuracy: 0.468200\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.6179 Validation Accuracy: 0.458800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.3890 Validation Accuracy: 0.470800\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.3643 Validation Accuracy: 0.485600\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.4232 Validation Accuracy: 0.481200\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.2696 Validation Accuracy: 0.491000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.5307 Validation Accuracy: 0.463800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.4104 Validation Accuracy: 0.481200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.3802 Validation Accuracy: 0.469800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.4789 Validation Accuracy: 0.445800\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.2490 Validation Accuracy: 0.513000\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.6941 Validation Accuracy: 0.426800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.3275 Validation Accuracy: 0.479600\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.4452 Validation Accuracy: 0.481000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.4259 Validation Accuracy: 0.494600\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.3228 Validation Accuracy: 0.454600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.6489 Validation Accuracy: 0.445800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.3993 Validation Accuracy: 0.486800\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.4278 Validation Accuracy: 0.482000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.4206 Validation Accuracy: 0.472200\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.2314 Validation Accuracy: 0.505600\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.6310 Validation Accuracy: 0.447200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.2765 Validation Accuracy: 0.482000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.3991 Validation Accuracy: 0.491400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.3946 Validation Accuracy: 0.462000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.2642 Validation Accuracy: 0.486000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.4991 Validation Accuracy: 0.469000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.3232 Validation Accuracy: 0.486000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.2956 Validation Accuracy: 0.486200\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.4117 Validation Accuracy: 0.478800\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.2474 Validation Accuracy: 0.502000\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.4545 Validation Accuracy: 0.480400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.2475 Validation Accuracy: 0.522800\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.2596 Validation Accuracy: 0.509600\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.3626 Validation Accuracy: 0.494400\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.2585 Validation Accuracy: 0.495200\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.4247 Validation Accuracy: 0.500200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.3419 Validation Accuracy: 0.479400\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.3529 Validation Accuracy: 0.493400\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.4054 Validation Accuracy: 0.460400\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.2364 Validation Accuracy: 0.506800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.4248 Validation Accuracy: 0.490000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.2242 Validation Accuracy: 0.515200\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.2158 Validation Accuracy: 0.512400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.3332 Validation Accuracy: 0.484800\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.2245 Validation Accuracy: 0.522400\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.4187 Validation Accuracy: 0.510200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.2057 Validation Accuracy: 0.512200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.2666 Validation Accuracy: 0.503400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.3801 Validation Accuracy: 0.496200\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.3222 Validation Accuracy: 0.493800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.6051 Validation Accuracy: 0.477600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.2489 Validation Accuracy: 0.516600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.3390 Validation Accuracy: 0.499000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.2626 Validation Accuracy: 0.511400\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.2179 Validation Accuracy: 0.517600\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.4321 Validation Accuracy: 0.507600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.1259 Validation Accuracy: 0.533800\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.3880 Validation Accuracy: 0.483400\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.3639 Validation Accuracy: 0.485600\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.1897 Validation Accuracy: 0.517000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.6978 Validation Accuracy: 0.456400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.2153 Validation Accuracy: 0.513800\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.2403 Validation Accuracy: 0.528400\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.2524 Validation Accuracy: 0.525600\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.1795 Validation Accuracy: 0.523400\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.4727 Validation Accuracy: 0.504000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.1754 Validation Accuracy: 0.522000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.3185 Validation Accuracy: 0.522200\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.2356 Validation Accuracy: 0.541400\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.2271 Validation Accuracy: 0.496800\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.3579 Validation Accuracy: 0.536200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.2657 Validation Accuracy: 0.523800\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.3118 Validation Accuracy: 0.505600\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.2628 Validation Accuracy: 0.519200\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.1742 Validation Accuracy: 0.522200\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.4725 Validation Accuracy: 0.499800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.2812 Validation Accuracy: 0.499600\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.2754 Validation Accuracy: 0.541400\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.2494 Validation Accuracy: 0.510000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.2427 Validation Accuracy: 0.496600\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.6531 Validation Accuracy: 0.454800\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.2774 Validation Accuracy: 0.531000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.2353 Validation Accuracy: 0.544600\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.1524 Validation Accuracy: 0.532400\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.2000 Validation Accuracy: 0.513800\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.2637 Validation Accuracy: 0.558200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.1622 Validation Accuracy: 0.527800\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.3306 Validation Accuracy: 0.536600\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.2131 Validation Accuracy: 0.533800\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.1149 Validation Accuracy: 0.558800\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.3688 Validation Accuracy: 0.532400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.1406 Validation Accuracy: 0.541200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.2671 Validation Accuracy: 0.536600\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.1735 Validation Accuracy: 0.546000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.1489 Validation Accuracy: 0.547200\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.3616 Validation Accuracy: 0.515000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.0915 Validation Accuracy: 0.554000\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.2416 Validation Accuracy: 0.538600\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.3295 Validation Accuracy: 0.505800\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.1658 Validation Accuracy: 0.537400\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.6256 Validation Accuracy: 0.460800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.1921 Validation Accuracy: 0.529200\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.2944 Validation Accuracy: 0.512600\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.2378 Validation Accuracy: 0.524800\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.0677 Validation Accuracy: 0.549200\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.3039 Validation Accuracy: 0.531400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.0746 Validation Accuracy: 0.555000\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.2446 Validation Accuracy: 0.524200\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.1656 Validation Accuracy: 0.549800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.1007 Validation Accuracy: 0.547200\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.3295 Validation Accuracy: 0.529400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.1841 Validation Accuracy: 0.518400\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.2544 Validation Accuracy: 0.524600\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     1.1353 Validation Accuracy: 0.531800\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.1127 Validation Accuracy: 0.552800\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.4408 Validation Accuracy: 0.504200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.0791 Validation Accuracy: 0.563600\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.2420 Validation Accuracy: 0.532200\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.1978 Validation Accuracy: 0.533400\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.1487 Validation Accuracy: 0.545400\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.4579 Validation Accuracy: 0.520200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.1112 Validation Accuracy: 0.542400\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.1661 Validation Accuracy: 0.547800\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     1.1327 Validation Accuracy: 0.549200\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.1552 Validation Accuracy: 0.546200\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.2845 Validation Accuracy: 0.535000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.1074 Validation Accuracy: 0.530200\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.2450 Validation Accuracy: 0.521800\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     1.2663 Validation Accuracy: 0.494600\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.2315 Validation Accuracy: 0.519400\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.3489 Validation Accuracy: 0.525600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.0678 Validation Accuracy: 0.569600\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.2528 Validation Accuracy: 0.499000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     1.1793 Validation Accuracy: 0.545400\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.2074 Validation Accuracy: 0.523400\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.3831 Validation Accuracy: 0.518000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.1428 Validation Accuracy: 0.558000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.2081 Validation Accuracy: 0.516200\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     1.1466 Validation Accuracy: 0.543000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.0723 Validation Accuracy: 0.551800\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.2418 Validation Accuracy: 0.547000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1656 Validation Accuracy: 0.527600\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.2223 Validation Accuracy: 0.539200\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     1.1565 Validation Accuracy: 0.556800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.1157 Validation Accuracy: 0.543800\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.3138 Validation Accuracy: 0.539600\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.2842 Validation Accuracy: 0.508600\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.1022 Validation Accuracy: 0.566000\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     1.2156 Validation Accuracy: 0.541800\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.1130 Validation Accuracy: 0.540600\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.3328 Validation Accuracy: 0.520200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.1898 Validation Accuracy: 0.547200\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.1620 Validation Accuracy: 0.559200\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     1.1463 Validation Accuracy: 0.558600\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.565200\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.2113 Validation Accuracy: 0.541400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.0869 Validation Accuracy: 0.562200\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.1719 Validation Accuracy: 0.560000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     1.1035 Validation Accuracy: 0.563400\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.0450 Validation Accuracy: 0.579000\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.3196 Validation Accuracy: 0.514200\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.0906 Validation Accuracy: 0.574200\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.2458 Validation Accuracy: 0.522200\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     1.1711 Validation Accuracy: 0.564400\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.1017 Validation Accuracy: 0.556000\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.4661 Validation Accuracy: 0.494400\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.0717 Validation Accuracy: 0.580000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.1256 Validation Accuracy: 0.557800\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     1.2008 Validation Accuracy: 0.552600\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.1139 Validation Accuracy: 0.549400\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.3056 Validation Accuracy: 0.532200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.0962 Validation Accuracy: 0.560200\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.1161 Validation Accuracy: 0.561800\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     1.2088 Validation Accuracy: 0.560200\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.0994 Validation Accuracy: 0.556000\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.3222 Validation Accuracy: 0.530800\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.1434 Validation Accuracy: 0.558000\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.1532 Validation Accuracy: 0.567000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     1.1699 Validation Accuracy: 0.543600\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.1610 Validation Accuracy: 0.553800\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.3628 Validation Accuracy: 0.540400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.1095 Validation Accuracy: 0.565200\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.1327 Validation Accuracy: 0.586200\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     1.1733 Validation Accuracy: 0.545000\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.0963 Validation Accuracy: 0.544400\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.4085 Validation Accuracy: 0.528600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.1665 Validation Accuracy: 0.567400\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.1301 Validation Accuracy: 0.554600\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     1.1117 Validation Accuracy: 0.559400\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.0730 Validation Accuracy: 0.581600\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.2418 Validation Accuracy: 0.523600\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.1445 Validation Accuracy: 0.554200\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.2321 Validation Accuracy: 0.528000\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     1.1061 Validation Accuracy: 0.577800\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.0496 Validation Accuracy: 0.574000\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.2259 Validation Accuracy: 0.553000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.0396 Validation Accuracy: 0.582400\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.0666 Validation Accuracy: 0.566600\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     1.1696 Validation Accuracy: 0.565000\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.0792 Validation Accuracy: 0.569800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.2053 Validation Accuracy: 0.555800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.1362 Validation Accuracy: 0.575800\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.1693 Validation Accuracy: 0.563400\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     1.0690 Validation Accuracy: 0.593400\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.0972 Validation Accuracy: 0.576000\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.1723 Validation Accuracy: 0.579800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.0874 Validation Accuracy: 0.588200\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     1.1774 Validation Accuracy: 0.551600\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     1.1182 Validation Accuracy: 0.563600\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.0970 Validation Accuracy: 0.561800\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.2744 Validation Accuracy: 0.552800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.9982 Validation Accuracy: 0.582000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.0795 Validation Accuracy: 0.583600\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     1.1195 Validation Accuracy: 0.565000\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.0303 Validation Accuracy: 0.593000\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.3326 Validation Accuracy: 0.556000\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.0624 Validation Accuracy: 0.585400\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     1.0827 Validation Accuracy: 0.578600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     1.1487 Validation Accuracy: 0.565200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     0.9523 Validation Accuracy: 0.606000\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.2831 Validation Accuracy: 0.551400\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.1599 Validation Accuracy: 0.561800\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.1245 Validation Accuracy: 0.561800\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     1.1073 Validation Accuracy: 0.585000\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.9716 Validation Accuracy: 0.595800\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.1360 Validation Accuracy: 0.585400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.0776 Validation Accuracy: 0.586400\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     1.2233 Validation Accuracy: 0.554800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     1.1654 Validation Accuracy: 0.552800\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.0227 Validation Accuracy: 0.585000\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.1334 Validation Accuracy: 0.569800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.9538 Validation Accuracy: 0.606000\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.2002 Validation Accuracy: 0.581200\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     1.2756 Validation Accuracy: 0.548800\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.0274 Validation Accuracy: 0.571800\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     1.2014 Validation Accuracy: 0.566000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.0619 Validation Accuracy: 0.590600\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.0464 Validation Accuracy: 0.597400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     1.0895 Validation Accuracy: 0.577400\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     0.8851 Validation Accuracy: 0.608200\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.3026 Validation Accuracy: 0.524000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.0657 Validation Accuracy: 0.606800\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     1.1588 Validation Accuracy: 0.550800\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     1.0817 Validation Accuracy: 0.559800\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.0350 Validation Accuracy: 0.570000\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     1.1871 Validation Accuracy: 0.552400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.0114 Validation Accuracy: 0.608800\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     1.0827 Validation Accuracy: 0.597400\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     1.0373 Validation Accuracy: 0.603400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.9286 Validation Accuracy: 0.620600\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     1.2581 Validation Accuracy: 0.537600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.0979 Validation Accuracy: 0.599600\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     1.2045 Validation Accuracy: 0.545400\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     1.1162 Validation Accuracy: 0.572000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.3075 Validation Accuracy: 0.477800\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     1.2364 Validation Accuracy: 0.555400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.0665 Validation Accuracy: 0.589600\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.9894 Validation Accuracy: 0.600200\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     1.0876 Validation Accuracy: 0.595400\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.9688 Validation Accuracy: 0.591200\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     1.1920 Validation Accuracy: 0.548600\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.0650 Validation Accuracy: 0.580400\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     1.0420 Validation Accuracy: 0.593400\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     1.1630 Validation Accuracy: 0.564000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.9266 Validation Accuracy: 0.589200\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     1.1898 Validation Accuracy: 0.571000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.9650 Validation Accuracy: 0.609600\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     1.1485 Validation Accuracy: 0.587400\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.9912 Validation Accuracy: 0.616000\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.9845 Validation Accuracy: 0.600800\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     1.1239 Validation Accuracy: 0.603200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.9733 Validation Accuracy: 0.605800\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.9736 Validation Accuracy: 0.599400\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     1.0383 Validation Accuracy: 0.585800\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.0527 Validation Accuracy: 0.572400\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     1.1949 Validation Accuracy: 0.567800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.0080 Validation Accuracy: 0.605800\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     1.0790 Validation Accuracy: 0.598200\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     1.1033 Validation Accuracy: 0.579200\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.0434 Validation Accuracy: 0.587800\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     1.1947 Validation Accuracy: 0.569600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.1468 Validation Accuracy: 0.571600\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     1.0722 Validation Accuracy: 0.576400\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     1.1656 Validation Accuracy: 0.550200\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.8866 Validation Accuracy: 0.613200\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     1.2371 Validation Accuracy: 0.584600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.0145 Validation Accuracy: 0.593200\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.9850 Validation Accuracy: 0.616400\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     1.1454 Validation Accuracy: 0.574000\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.0463 Validation Accuracy: 0.591000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     1.2896 Validation Accuracy: 0.575800\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.0463 Validation Accuracy: 0.596400\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     1.1129 Validation Accuracy: 0.582400\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     1.0733 Validation Accuracy: 0.595600\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.9591 Validation Accuracy: 0.603600\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     1.1296 Validation Accuracy: 0.602200\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.9654 Validation Accuracy: 0.606200\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     1.0494 Validation Accuracy: 0.606800\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     1.1238 Validation Accuracy: 0.577400\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.9151 Validation Accuracy: 0.609800\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     1.3529 Validation Accuracy: 0.552400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.0377 Validation Accuracy: 0.584400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     1.1727 Validation Accuracy: 0.570400\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     1.0724 Validation Accuracy: 0.604600\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.9769 Validation Accuracy: 0.602600\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     1.2339 Validation Accuracy: 0.551200\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.9425 Validation Accuracy: 0.601000\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     1.2092 Validation Accuracy: 0.557400\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.9935 Validation Accuracy: 0.593600\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.9678 Validation Accuracy: 0.589000\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     1.1622 Validation Accuracy: 0.603800\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.9477 Validation Accuracy: 0.612200\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     1.1847 Validation Accuracy: 0.609800\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.9802 Validation Accuracy: 0.592000\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.0708 Validation Accuracy: 0.583800\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     1.1628 Validation Accuracy: 0.589000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0960 Validation Accuracy: 0.602200\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     1.1226 Validation Accuracy: 0.574200\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.9975 Validation Accuracy: 0.615200\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.8426 Validation Accuracy: 0.618400\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     1.0220 Validation Accuracy: 0.594200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.9445 Validation Accuracy: 0.602600\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     1.0551 Validation Accuracy: 0.592200\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     1.0518 Validation Accuracy: 0.582000\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.8644 Validation Accuracy: 0.610800\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     1.0711 Validation Accuracy: 0.588600\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     0.8776 Validation Accuracy: 0.615000\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     1.1232 Validation Accuracy: 0.613400\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     1.0053 Validation Accuracy: 0.594600\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     0.8418 Validation Accuracy: 0.616200\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     1.1201 Validation Accuracy: 0.585400\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     0.9355 Validation Accuracy: 0.598600\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     1.0166 Validation Accuracy: 0.621800\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     0.9106 Validation Accuracy: 0.615000\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     0.9888 Validation Accuracy: 0.617800\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     1.0492 Validation Accuracy: 0.597200\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     0.9560 Validation Accuracy: 0.594400\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     1.1050 Validation Accuracy: 0.608200\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     1.0058 Validation Accuracy: 0.603000\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     0.8920 Validation Accuracy: 0.628600\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     1.0549 Validation Accuracy: 0.598000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     0.9138 Validation Accuracy: 0.597800\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     1.0959 Validation Accuracy: 0.617000\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     0.9528 Validation Accuracy: 0.606200\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     0.9942 Validation Accuracy: 0.622400\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     1.1055 Validation Accuracy: 0.614200\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.0430 Validation Accuracy: 0.595600\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     1.0844 Validation Accuracy: 0.617800\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     0.9750 Validation Accuracy: 0.614000\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     0.8538 Validation Accuracy: 0.639200\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     1.1104 Validation Accuracy: 0.585800\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     0.9655 Validation Accuracy: 0.589400\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     1.1209 Validation Accuracy: 0.576400\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     1.0766 Validation Accuracy: 0.601200\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     0.9162 Validation Accuracy: 0.605200\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     1.1126 Validation Accuracy: 0.596600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     0.9262 Validation Accuracy: 0.604800\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     1.0404 Validation Accuracy: 0.612600\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     0.9577 Validation Accuracy: 0.622800\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     0.8587 Validation Accuracy: 0.614600\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     1.1518 Validation Accuracy: 0.589800\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     0.8904 Validation Accuracy: 0.618000\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     1.1192 Validation Accuracy: 0.601600\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     0.9950 Validation Accuracy: 0.594000\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     0.8586 Validation Accuracy: 0.624400\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     1.1325 Validation Accuracy: 0.562600\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     0.8579 Validation Accuracy: 0.631800\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     1.0608 Validation Accuracy: 0.571600\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     1.0363 Validation Accuracy: 0.613600\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     0.9383 Validation Accuracy: 0.609600\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     1.2306 Validation Accuracy: 0.564000\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.8822 Validation Accuracy: 0.635600\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     1.0783 Validation Accuracy: 0.596400\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     0.9039 Validation Accuracy: 0.611200\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     0.8898 Validation Accuracy: 0.636400\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     1.0087 Validation Accuracy: 0.602000\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.8985 Validation Accuracy: 0.609000\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     1.2169 Validation Accuracy: 0.567800\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     1.0134 Validation Accuracy: 0.603400\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     0.8953 Validation Accuracy: 0.612200\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     1.1023 Validation Accuracy: 0.601600\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.8852 Validation Accuracy: 0.644600\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     1.0996 Validation Accuracy: 0.588400\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     0.8752 Validation Accuracy: 0.624000\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     0.8806 Validation Accuracy: 0.623600\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     1.0465 Validation Accuracy: 0.611600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     0.8986 Validation Accuracy: 0.623400\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     1.0510 Validation Accuracy: 0.609800\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     0.8819 Validation Accuracy: 0.634800\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     1.0171 Validation Accuracy: 0.620600\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     1.1033 Validation Accuracy: 0.601800\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.8972 Validation Accuracy: 0.613800\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     1.0605 Validation Accuracy: 0.609000\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     0.8932 Validation Accuracy: 0.632200\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     0.8245 Validation Accuracy: 0.629600\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     1.3877 Validation Accuracy: 0.545400\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     0.8652 Validation Accuracy: 0.628600\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     1.0214 Validation Accuracy: 0.632000\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     0.8770 Validation Accuracy: 0.621200\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     0.8837 Validation Accuracy: 0.611400\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     1.1404 Validation Accuracy: 0.603400\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.8616 Validation Accuracy: 0.632400\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     1.0042 Validation Accuracy: 0.614400\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     0.9806 Validation Accuracy: 0.614600\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     0.8643 Validation Accuracy: 0.629800\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     1.1133 Validation Accuracy: 0.598400\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     0.8984 Validation Accuracy: 0.634400\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     1.0206 Validation Accuracy: 0.634200\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     0.8795 Validation Accuracy: 0.636200\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     0.7726 Validation Accuracy: 0.642400\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     1.0977 Validation Accuracy: 0.624000\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.8698 Validation Accuracy: 0.638200\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     0.9802 Validation Accuracy: 0.638400\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     0.9254 Validation Accuracy: 0.611600\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     0.9841 Validation Accuracy: 0.616000\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     1.0505 Validation Accuracy: 0.631400\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     0.9645 Validation Accuracy: 0.622600\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     1.0327 Validation Accuracy: 0.643000\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     0.8785 Validation Accuracy: 0.632400\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     0.9712 Validation Accuracy: 0.616600\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     1.0800 Validation Accuracy: 0.611200\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.9184 Validation Accuracy: 0.638400\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     1.1890 Validation Accuracy: 0.607000\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     0.9104 Validation Accuracy: 0.636600\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     0.8853 Validation Accuracy: 0.635000\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     1.1188 Validation Accuracy: 0.588200\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.9055 Validation Accuracy: 0.636000\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     1.1540 Validation Accuracy: 0.613200\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     0.9344 Validation Accuracy: 0.589600\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     0.8669 Validation Accuracy: 0.633400\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     1.0675 Validation Accuracy: 0.613000\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     0.8734 Validation Accuracy: 0.635000\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     1.1379 Validation Accuracy: 0.615000\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     0.9326 Validation Accuracy: 0.631800\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     0.8353 Validation Accuracy: 0.634600\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     0.9425 Validation Accuracy: 0.630600\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.9301 Validation Accuracy: 0.626400\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     1.0834 Validation Accuracy: 0.622800\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     0.9623 Validation Accuracy: 0.622600\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     0.7379 Validation Accuracy: 0.637800\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     1.1246 Validation Accuracy: 0.616600\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.9164 Validation Accuracy: 0.630400\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     1.0818 Validation Accuracy: 0.611800\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     1.0012 Validation Accuracy: 0.619400\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     0.8946 Validation Accuracy: 0.619800\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     1.0414 Validation Accuracy: 0.639800\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.8864 Validation Accuracy: 0.637600\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     0.9548 Validation Accuracy: 0.624400\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     0.9071 Validation Accuracy: 0.638800\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     0.7932 Validation Accuracy: 0.637400\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     1.2423 Validation Accuracy: 0.588800\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.8298 Validation Accuracy: 0.649000\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     0.8786 Validation Accuracy: 0.626600\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     0.9543 Validation Accuracy: 0.619000\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     0.7909 Validation Accuracy: 0.639000\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     1.0320 Validation Accuracy: 0.643600\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.8891 Validation Accuracy: 0.633000\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     1.0650 Validation Accuracy: 0.623600\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     0.9882 Validation Accuracy: 0.598800\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     0.9244 Validation Accuracy: 0.601000\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     1.1234 Validation Accuracy: 0.603400\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.8710 Validation Accuracy: 0.643000\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     0.9989 Validation Accuracy: 0.638600\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     0.8762 Validation Accuracy: 0.643200\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     0.8214 Validation Accuracy: 0.646200\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     1.0250 Validation Accuracy: 0.621000\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.8831 Validation Accuracy: 0.641400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     0.8990 Validation Accuracy: 0.656800\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     0.8737 Validation Accuracy: 0.639400\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     0.8722 Validation Accuracy: 0.631600\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     1.0892 Validation Accuracy: 0.645600\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.8555 Validation Accuracy: 0.650000\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     1.0441 Validation Accuracy: 0.604600\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     0.8455 Validation Accuracy: 0.654000\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     0.8071 Validation Accuracy: 0.641400\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     1.1297 Validation Accuracy: 0.634600\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.9163 Validation Accuracy: 0.626000\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     0.9408 Validation Accuracy: 0.624400\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     0.9104 Validation Accuracy: 0.619200\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     0.7556 Validation Accuracy: 0.642400\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     1.1417 Validation Accuracy: 0.610200\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.8840 Validation Accuracy: 0.645200\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     1.0086 Validation Accuracy: 0.611400\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     0.8927 Validation Accuracy: 0.626600\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     0.8658 Validation Accuracy: 0.621200\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     1.1740 Validation Accuracy: 0.602000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.8909 Validation Accuracy: 0.643800\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     0.9319 Validation Accuracy: 0.639600\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     0.8743 Validation Accuracy: 0.655000\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     0.8313 Validation Accuracy: 0.636200\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     0.9932 Validation Accuracy: 0.638000\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.8065 Validation Accuracy: 0.649800\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     0.9497 Validation Accuracy: 0.643200\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     0.9162 Validation Accuracy: 0.627400\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     0.8252 Validation Accuracy: 0.630200\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     1.0395 Validation Accuracy: 0.607400\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.8810 Validation Accuracy: 0.648000\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     1.1597 Validation Accuracy: 0.584400\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     0.8868 Validation Accuracy: 0.630400\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     0.8766 Validation Accuracy: 0.638400\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     1.0017 Validation Accuracy: 0.651800\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.8236 Validation Accuracy: 0.654600\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     0.9414 Validation Accuracy: 0.629800\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     0.8652 Validation Accuracy: 0.639400\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     0.8734 Validation Accuracy: 0.638600\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     1.0450 Validation Accuracy: 0.627000\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.9027 Validation Accuracy: 0.628200\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     0.8723 Validation Accuracy: 0.633400\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     0.9244 Validation Accuracy: 0.612200\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     0.7853 Validation Accuracy: 0.621000\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     1.2109 Validation Accuracy: 0.567800\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.8539 Validation Accuracy: 0.649400\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     0.9814 Validation Accuracy: 0.633000\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     0.8284 Validation Accuracy: 0.643000\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     0.9137 Validation Accuracy: 0.615000\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     1.1066 Validation Accuracy: 0.618000\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.8468 Validation Accuracy: 0.643400\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     1.1513 Validation Accuracy: 0.618400\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     0.8911 Validation Accuracy: 0.642000\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     0.8753 Validation Accuracy: 0.623200\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     1.0239 Validation Accuracy: 0.634000\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.8338 Validation Accuracy: 0.642000\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     1.0950 Validation Accuracy: 0.610600\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     0.8947 Validation Accuracy: 0.653000\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     0.7718 Validation Accuracy: 0.644600\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     0.9082 Validation Accuracy: 0.655000\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.8008 Validation Accuracy: 0.664000\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     0.9001 Validation Accuracy: 0.646200\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     1.0892 Validation Accuracy: 0.597200\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     0.8713 Validation Accuracy: 0.606600\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     0.9771 Validation Accuracy: 0.631000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.8396 Validation Accuracy: 0.644600\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     0.8245 Validation Accuracy: 0.645600\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     0.8158 Validation Accuracy: 0.648800\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     0.7538 Validation Accuracy: 0.659400\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     0.9464 Validation Accuracy: 0.646400\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.8041 Validation Accuracy: 0.650200\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     0.9924 Validation Accuracy: 0.659200\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     0.9017 Validation Accuracy: 0.609200\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     0.7307 Validation Accuracy: 0.655200\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     1.1326 Validation Accuracy: 0.620400\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.8489 Validation Accuracy: 0.644200\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     0.8929 Validation Accuracy: 0.646600\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     0.7618 Validation Accuracy: 0.667800\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     0.7924 Validation Accuracy: 0.664400\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     1.0825 Validation Accuracy: 0.628200\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.9006 Validation Accuracy: 0.638800\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     1.1261 Validation Accuracy: 0.596800\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     0.8288 Validation Accuracy: 0.648400\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     0.8680 Validation Accuracy: 0.643600\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     1.1347 Validation Accuracy: 0.606400\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.8577 Validation Accuracy: 0.644600\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     0.8171 Validation Accuracy: 0.633800\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     0.8259 Validation Accuracy: 0.639400\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     0.8377 Validation Accuracy: 0.641400\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     1.0243 Validation Accuracy: 0.646800\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.9514 Validation Accuracy: 0.605000\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     1.0364 Validation Accuracy: 0.610400\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     0.8265 Validation Accuracy: 0.638000\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     0.8860 Validation Accuracy: 0.616000\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     0.9694 Validation Accuracy: 0.651000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.8756 Validation Accuracy: 0.639200\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     0.8701 Validation Accuracy: 0.630000\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     0.8336 Validation Accuracy: 0.649800\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     0.8879 Validation Accuracy: 0.599800\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     0.9816 Validation Accuracy: 0.640200\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.8644 Validation Accuracy: 0.651600\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     1.0918 Validation Accuracy: 0.623800\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     0.8726 Validation Accuracy: 0.621200\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     0.7741 Validation Accuracy: 0.652800\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     0.9197 Validation Accuracy: 0.659600\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.8990 Validation Accuracy: 0.644200\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     0.8429 Validation Accuracy: 0.645000\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     0.8107 Validation Accuracy: 0.650200\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     0.7574 Validation Accuracy: 0.616600\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     1.1138 Validation Accuracy: 0.610800\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.8274 Validation Accuracy: 0.645400\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     1.0060 Validation Accuracy: 0.617400\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     0.7404 Validation Accuracy: 0.648800\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     0.7830 Validation Accuracy: 0.642200\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     1.0134 Validation Accuracy: 0.632600\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.8694 Validation Accuracy: 0.644200\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     0.9025 Validation Accuracy: 0.638600\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     0.9048 Validation Accuracy: 0.600800\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     0.9184 Validation Accuracy: 0.604000\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     1.0621 Validation Accuracy: 0.602400\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.9298 Validation Accuracy: 0.619200\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     0.8340 Validation Accuracy: 0.628400\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     0.7995 Validation Accuracy: 0.662000\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     0.8328 Validation Accuracy: 0.626200\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     1.0558 Validation Accuracy: 0.637000\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.8256 Validation Accuracy: 0.653800\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     0.8800 Validation Accuracy: 0.647200\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     0.8074 Validation Accuracy: 0.654400\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     0.7980 Validation Accuracy: 0.648800\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     0.9647 Validation Accuracy: 0.630000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.8828 Validation Accuracy: 0.641200\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     0.8182 Validation Accuracy: 0.645200\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     0.8794 Validation Accuracy: 0.601000\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     0.7754 Validation Accuracy: 0.658800\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     0.9188 Validation Accuracy: 0.640000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.7995 Validation Accuracy: 0.666600\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     0.9516 Validation Accuracy: 0.626600\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     0.7770 Validation Accuracy: 0.642400\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     0.8308 Validation Accuracy: 0.637400\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     0.9225 Validation Accuracy: 0.658600\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.8882 Validation Accuracy: 0.646600\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     0.8694 Validation Accuracy: 0.635800\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     0.7755 Validation Accuracy: 0.642600\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     0.8938 Validation Accuracy: 0.631600\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     1.0085 Validation Accuracy: 0.647200\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.8644 Validation Accuracy: 0.670600\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     0.9202 Validation Accuracy: 0.634000\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     0.7535 Validation Accuracy: 0.660800\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     0.8796 Validation Accuracy: 0.631600\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     0.9745 Validation Accuracy: 0.620000\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.8461 Validation Accuracy: 0.622800\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     0.8241 Validation Accuracy: 0.646200\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     0.8870 Validation Accuracy: 0.611200\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     0.7422 Validation Accuracy: 0.650600\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     0.9913 Validation Accuracy: 0.638000\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.8352 Validation Accuracy: 0.662000\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     0.9810 Validation Accuracy: 0.625000\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     0.7476 Validation Accuracy: 0.665600\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     0.8656 Validation Accuracy: 0.626400\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     1.0465 Validation Accuracy: 0.613800\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.8390 Validation Accuracy: 0.664800\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     0.9811 Validation Accuracy: 0.637400\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     0.8293 Validation Accuracy: 0.631200\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     0.8322 Validation Accuracy: 0.631400\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     1.0147 Validation Accuracy: 0.629800\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.7805 Validation Accuracy: 0.679400\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     0.8510 Validation Accuracy: 0.655200\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     0.7472 Validation Accuracy: 0.648800\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     0.7151 Validation Accuracy: 0.660400\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     1.0367 Validation Accuracy: 0.619400\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.9039 Validation Accuracy: 0.648000\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     0.9930 Validation Accuracy: 0.623400\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     0.7863 Validation Accuracy: 0.651800\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     0.8082 Validation Accuracy: 0.651200\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     1.0277 Validation Accuracy: 0.623000\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.8519 Validation Accuracy: 0.661800\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     0.8766 Validation Accuracy: 0.653200\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     0.8103 Validation Accuracy: 0.635800\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     0.7453 Validation Accuracy: 0.645600\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     0.9472 Validation Accuracy: 0.641000\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.8460 Validation Accuracy: 0.627400\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     0.8671 Validation Accuracy: 0.649800\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     0.8121 Validation Accuracy: 0.654200\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     0.9575 Validation Accuracy: 0.574200\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     1.0278 Validation Accuracy: 0.642200\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.8998 Validation Accuracy: 0.635400\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     0.9461 Validation Accuracy: 0.638600\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     0.7758 Validation Accuracy: 0.654400\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     0.6926 Validation Accuracy: 0.650000\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     0.9486 Validation Accuracy: 0.646400\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.9377 Validation Accuracy: 0.639200\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     1.0176 Validation Accuracy: 0.632000\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     0.8163 Validation Accuracy: 0.657400\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     0.7255 Validation Accuracy: 0.657000\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     1.0765 Validation Accuracy: 0.623400\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.7844 Validation Accuracy: 0.672600\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     0.9425 Validation Accuracy: 0.649000\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     0.7445 Validation Accuracy: 0.657800\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     0.8526 Validation Accuracy: 0.608000\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     1.2864 Validation Accuracy: 0.585200\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.8497 Validation Accuracy: 0.671600\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     1.0251 Validation Accuracy: 0.651200\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     0.8374 Validation Accuracy: 0.633600\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     0.8067 Validation Accuracy: 0.633600\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     0.8557 Validation Accuracy: 0.669600\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.8288 Validation Accuracy: 0.643400\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     0.8357 Validation Accuracy: 0.670600\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     0.7629 Validation Accuracy: 0.663600\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     0.7320 Validation Accuracy: 0.663800\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     0.9758 Validation Accuracy: 0.645600\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.8065 Validation Accuracy: 0.657200\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     0.8646 Validation Accuracy: 0.655000\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     0.8692 Validation Accuracy: 0.641000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     0.7276 Validation Accuracy: 0.663200\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     0.9340 Validation Accuracy: 0.647400\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.8341 Validation Accuracy: 0.645800\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     0.9438 Validation Accuracy: 0.658200\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     0.9674 Validation Accuracy: 0.613000\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     0.7064 Validation Accuracy: 0.660600\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     0.9173 Validation Accuracy: 0.643400\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.7945 Validation Accuracy: 0.667200\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     0.8467 Validation Accuracy: 0.657800\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     1.1089 Validation Accuracy: 0.570800\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     0.7277 Validation Accuracy: 0.670200\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     0.9613 Validation Accuracy: 0.658400\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.8150 Validation Accuracy: 0.669000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     0.9435 Validation Accuracy: 0.638200\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     0.8885 Validation Accuracy: 0.638600\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     0.7497 Validation Accuracy: 0.667400\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     0.9056 Validation Accuracy: 0.647400\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.7870 Validation Accuracy: 0.672000\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     1.0283 Validation Accuracy: 0.610200\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     0.8063 Validation Accuracy: 0.657200\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     0.8171 Validation Accuracy: 0.647000\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     1.0611 Validation Accuracy: 0.642800\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.8437 Validation Accuracy: 0.647400\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     0.9024 Validation Accuracy: 0.651400\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     0.7181 Validation Accuracy: 0.666800\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     0.7882 Validation Accuracy: 0.645800\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     0.8215 Validation Accuracy: 0.677800\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.8572 Validation Accuracy: 0.661200\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     1.0355 Validation Accuracy: 0.623600\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     0.9573 Validation Accuracy: 0.608000\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     0.8396 Validation Accuracy: 0.649200\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     0.8187 Validation Accuracy: 0.660600\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.8649 Validation Accuracy: 0.639800\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     0.8708 Validation Accuracy: 0.665000\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     0.7410 Validation Accuracy: 0.664600\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     0.6813 Validation Accuracy: 0.665400\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     1.0471 Validation Accuracy: 0.657000\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.8119 Validation Accuracy: 0.655000\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     0.7745 Validation Accuracy: 0.672800\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     0.8568 Validation Accuracy: 0.628800\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     0.8090 Validation Accuracy: 0.631200\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     0.9410 Validation Accuracy: 0.657200\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.8329 Validation Accuracy: 0.654600\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     0.8812 Validation Accuracy: 0.648200\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     0.8182 Validation Accuracy: 0.643800\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     0.7801 Validation Accuracy: 0.648400\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     1.0563 Validation Accuracy: 0.612200\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.8061 Validation Accuracy: 0.666800\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     0.7768 Validation Accuracy: 0.649800\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     0.8506 Validation Accuracy: 0.627600\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     0.8713 Validation Accuracy: 0.621000\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     0.9707 Validation Accuracy: 0.641200\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.7959 Validation Accuracy: 0.661400\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     0.9387 Validation Accuracy: 0.634400\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     0.8075 Validation Accuracy: 0.653200\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     0.7432 Validation Accuracy: 0.665400\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     0.9417 Validation Accuracy: 0.670200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.7654 Validation Accuracy: 0.667800\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     0.9224 Validation Accuracy: 0.636800\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     0.7842 Validation Accuracy: 0.659600\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     0.7207 Validation Accuracy: 0.663200\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     0.9475 Validation Accuracy: 0.666400\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.7812 Validation Accuracy: 0.662400\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     0.8613 Validation Accuracy: 0.675000\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     0.8158 Validation Accuracy: 0.652400\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     0.8252 Validation Accuracy: 0.647800\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     1.2440 Validation Accuracy: 0.547000\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.8428 Validation Accuracy: 0.640200\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     1.0395 Validation Accuracy: 0.633600\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     0.8133 Validation Accuracy: 0.633200\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     0.6461 Validation Accuracy: 0.670000\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     0.8121 Validation Accuracy: 0.677200\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.8820 Validation Accuracy: 0.650000\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     1.0451 Validation Accuracy: 0.620400\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     0.7678 Validation Accuracy: 0.634800\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     0.7020 Validation Accuracy: 0.661400\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     0.9975 Validation Accuracy: 0.622600\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.7549 Validation Accuracy: 0.668600\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     0.8652 Validation Accuracy: 0.659000\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     0.7814 Validation Accuracy: 0.639200\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     0.5829 Validation Accuracy: 0.679200\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     0.9576 Validation Accuracy: 0.650000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.7396 Validation Accuracy: 0.668400\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     0.8433 Validation Accuracy: 0.675000\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     0.7717 Validation Accuracy: 0.631000\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     0.6751 Validation Accuracy: 0.664000\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     0.8760 Validation Accuracy: 0.677400\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.7084 Validation Accuracy: 0.677600\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     0.9555 Validation Accuracy: 0.651800\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     0.7812 Validation Accuracy: 0.642000\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     0.7578 Validation Accuracy: 0.671600\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     0.8391 Validation Accuracy: 0.664400\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.7263 Validation Accuracy: 0.678600\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     1.0151 Validation Accuracy: 0.634400\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     0.7676 Validation Accuracy: 0.662000\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     0.8170 Validation Accuracy: 0.652600\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     0.9627 Validation Accuracy: 0.655000\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.7366 Validation Accuracy: 0.680400\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     0.8364 Validation Accuracy: 0.672200\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     0.7683 Validation Accuracy: 0.656800\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     0.7511 Validation Accuracy: 0.657600\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     0.9554 Validation Accuracy: 0.648200\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.7638 Validation Accuracy: 0.671600\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     0.9275 Validation Accuracy: 0.653200\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     0.7738 Validation Accuracy: 0.653400\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     0.6703 Validation Accuracy: 0.668200\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     0.8946 Validation Accuracy: 0.662000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.7587 Validation Accuracy: 0.686600\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     0.8905 Validation Accuracy: 0.661600\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     0.7752 Validation Accuracy: 0.648600\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     0.7400 Validation Accuracy: 0.655800\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     0.9752 Validation Accuracy: 0.657400\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.7784 Validation Accuracy: 0.675200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     0.8060 Validation Accuracy: 0.665200\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     0.7312 Validation Accuracy: 0.649800\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     0.8332 Validation Accuracy: 0.645400\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     0.9683 Validation Accuracy: 0.660200\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.7832 Validation Accuracy: 0.664000\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     0.9305 Validation Accuracy: 0.665000\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     0.7357 Validation Accuracy: 0.673200\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     0.7191 Validation Accuracy: 0.685800\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     1.0098 Validation Accuracy: 0.651600\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.8604 Validation Accuracy: 0.663000\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     0.8569 Validation Accuracy: 0.667600\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     0.7051 Validation Accuracy: 0.671800\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     0.7164 Validation Accuracy: 0.658200\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     0.9629 Validation Accuracy: 0.668200\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.8125 Validation Accuracy: 0.658800\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     0.8269 Validation Accuracy: 0.673000\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     0.7752 Validation Accuracy: 0.659400\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     0.7287 Validation Accuracy: 0.674200\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     1.0672 Validation Accuracy: 0.648400\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.8655 Validation Accuracy: 0.656000\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     0.8264 Validation Accuracy: 0.677000\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     0.7576 Validation Accuracy: 0.655000\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     0.7831 Validation Accuracy: 0.651000\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     1.0420 Validation Accuracy: 0.664800\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.7857 Validation Accuracy: 0.673600\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     0.9673 Validation Accuracy: 0.646800\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     0.9158 Validation Accuracy: 0.608000\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     0.6959 Validation Accuracy: 0.680400\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     0.9649 Validation Accuracy: 0.667200\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.7661 Validation Accuracy: 0.679200\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     0.9015 Validation Accuracy: 0.657200\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     0.6946 Validation Accuracy: 0.658600\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     0.8154 Validation Accuracy: 0.667000\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     0.9958 Validation Accuracy: 0.660800\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     0.7864 Validation Accuracy: 0.670200\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     0.8961 Validation Accuracy: 0.651200\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     0.8033 Validation Accuracy: 0.622400\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     0.8768 Validation Accuracy: 0.660000\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     0.9888 Validation Accuracy: 0.659000\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     0.7997 Validation Accuracy: 0.661200\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     0.9280 Validation Accuracy: 0.647600\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     0.7913 Validation Accuracy: 0.647000\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     0.7621 Validation Accuracy: 0.660800\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     0.8851 Validation Accuracy: 0.664400\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     0.8042 Validation Accuracy: 0.669200\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     0.8248 Validation Accuracy: 0.656200\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     0.6608 Validation Accuracy: 0.668400\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     0.8012 Validation Accuracy: 0.667000\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     1.0546 Validation Accuracy: 0.629200\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     0.7837 Validation Accuracy: 0.650800\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     0.9756 Validation Accuracy: 0.629800\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     0.8013 Validation Accuracy: 0.629600\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     0.6755 Validation Accuracy: 0.672600\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     0.9160 Validation Accuracy: 0.660800\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     0.7831 Validation Accuracy: 0.669800\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     0.9954 Validation Accuracy: 0.603000\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     0.8417 Validation Accuracy: 0.607000\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     0.8783 Validation Accuracy: 0.660200\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     0.9293 Validation Accuracy: 0.651600\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     0.7886 Validation Accuracy: 0.671000\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     0.7955 Validation Accuracy: 0.679800\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     0.7664 Validation Accuracy: 0.638800\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     0.8402 Validation Accuracy: 0.661200\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     0.9867 Validation Accuracy: 0.656800\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     0.8354 Validation Accuracy: 0.673600\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     0.8802 Validation Accuracy: 0.658400\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     0.7129 Validation Accuracy: 0.649200\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     1.0997 Validation Accuracy: 0.581000\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     0.9019 Validation Accuracy: 0.678200\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     0.7192 Validation Accuracy: 0.675400\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     0.8688 Validation Accuracy: 0.631800\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     0.6520 Validation Accuracy: 0.683000\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     0.7354 Validation Accuracy: 0.684600\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     0.7677 Validation Accuracy: 0.677200\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     0.7495 Validation Accuracy: 0.674600\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     0.8600 Validation Accuracy: 0.644000\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     0.7990 Validation Accuracy: 0.634400\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     0.7556 Validation Accuracy: 0.674400\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     1.0150 Validation Accuracy: 0.634400\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     0.8632 Validation Accuracy: 0.656000\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     0.8470 Validation Accuracy: 0.660600\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     0.7098 Validation Accuracy: 0.642800\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     0.9104 Validation Accuracy: 0.654200\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     0.8979 Validation Accuracy: 0.669200\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     0.8310 Validation Accuracy: 0.665400\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     0.8117 Validation Accuracy: 0.660600\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     0.6896 Validation Accuracy: 0.669600\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     0.8529 Validation Accuracy: 0.671200\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     1.0434 Validation Accuracy: 0.657200\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     0.8631 Validation Accuracy: 0.678400\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     0.9929 Validation Accuracy: 0.653400\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     0.6507 Validation Accuracy: 0.675600\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     0.8125 Validation Accuracy: 0.655000\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     0.9455 Validation Accuracy: 0.659000\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     0.7895 Validation Accuracy: 0.665400\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     0.9858 Validation Accuracy: 0.638000\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     0.7420 Validation Accuracy: 0.658800\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     0.7641 Validation Accuracy: 0.685400\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     0.9751 Validation Accuracy: 0.644600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     0.7161 Validation Accuracy: 0.671400\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     0.8932 Validation Accuracy: 0.663600\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     0.6369 Validation Accuracy: 0.666000\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     0.8386 Validation Accuracy: 0.672000\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     1.0259 Validation Accuracy: 0.663800\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     0.7524 Validation Accuracy: 0.688000\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     1.0087 Validation Accuracy: 0.619400\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     0.8878 Validation Accuracy: 0.602800\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     0.8008 Validation Accuracy: 0.664400\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     0.8862 Validation Accuracy: 0.672200\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     0.7440 Validation Accuracy: 0.681600\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     0.7963 Validation Accuracy: 0.657600\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     0.7597 Validation Accuracy: 0.642800\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     0.8333 Validation Accuracy: 0.661600\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     0.8709 Validation Accuracy: 0.666200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     0.7329 Validation Accuracy: 0.679800\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     0.7482 Validation Accuracy: 0.674400\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     0.8215 Validation Accuracy: 0.656400\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     0.7621 Validation Accuracy: 0.660600\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     0.9196 Validation Accuracy: 0.671200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     0.7493 Validation Accuracy: 0.668600\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     0.7786 Validation Accuracy: 0.662600\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     0.6833 Validation Accuracy: 0.654800\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     0.7220 Validation Accuracy: 0.681400\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     0.8357 Validation Accuracy: 0.682800\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     0.7876 Validation Accuracy: 0.663000\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     0.9233 Validation Accuracy: 0.653800\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     0.6341 Validation Accuracy: 0.657200\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     0.7028 Validation Accuracy: 0.686000\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     0.9081 Validation Accuracy: 0.659000\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     0.7751 Validation Accuracy: 0.688600\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     0.7890 Validation Accuracy: 0.673200\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     0.6460 Validation Accuracy: 0.674600\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     0.7756 Validation Accuracy: 0.678800\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     0.9435 Validation Accuracy: 0.638600\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     0.7531 Validation Accuracy: 0.686800\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     0.8117 Validation Accuracy: 0.662600\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     0.7253 Validation Accuracy: 0.644200\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     0.7436 Validation Accuracy: 0.666400\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     1.1419 Validation Accuracy: 0.613200\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     0.7694 Validation Accuracy: 0.679600\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     1.0028 Validation Accuracy: 0.633000\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     0.7087 Validation Accuracy: 0.660200\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     0.9674 Validation Accuracy: 0.609400\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     0.9940 Validation Accuracy: 0.654800\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     0.7569 Validation Accuracy: 0.667000\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     1.0753 Validation Accuracy: 0.576800\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     0.7401 Validation Accuracy: 0.637200\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     0.7360 Validation Accuracy: 0.659000\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     0.9460 Validation Accuracy: 0.646600\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     0.8194 Validation Accuracy: 0.669000\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     0.8747 Validation Accuracy: 0.648800\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     0.6376 Validation Accuracy: 0.673000\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     0.7338 Validation Accuracy: 0.664400\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     0.9903 Validation Accuracy: 0.644600\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     0.7179 Validation Accuracy: 0.682800\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     0.9035 Validation Accuracy: 0.673200\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     0.6662 Validation Accuracy: 0.660000\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     0.7276 Validation Accuracy: 0.664200\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     0.8813 Validation Accuracy: 0.661400\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     0.9600 Validation Accuracy: 0.627200\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     0.8622 Validation Accuracy: 0.676600\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     0.8446 Validation Accuracy: 0.621400\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     0.7678 Validation Accuracy: 0.667400\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     0.8826 Validation Accuracy: 0.677200\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     0.7513 Validation Accuracy: 0.680800\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     1.0423 Validation Accuracy: 0.629800\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     0.6479 Validation Accuracy: 0.657000\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     0.8633 Validation Accuracy: 0.629600\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     0.8953 Validation Accuracy: 0.628600\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     0.7140 Validation Accuracy: 0.687400\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     0.8586 Validation Accuracy: 0.666000\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     0.6437 Validation Accuracy: 0.648800\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     0.7096 Validation Accuracy: 0.690800\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     0.8792 Validation Accuracy: 0.645000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     0.7245 Validation Accuracy: 0.678000\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     0.7823 Validation Accuracy: 0.671600\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     0.8038 Validation Accuracy: 0.646400\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     0.7855 Validation Accuracy: 0.657000\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     0.9170 Validation Accuracy: 0.649600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     0.7503 Validation Accuracy: 0.674600\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     0.9098 Validation Accuracy: 0.651600\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     0.7673 Validation Accuracy: 0.648000\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     0.6499 Validation Accuracy: 0.669400\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     0.8169 Validation Accuracy: 0.680800\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     0.7836 Validation Accuracy: 0.681600\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     0.8915 Validation Accuracy: 0.661000\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     0.6316 Validation Accuracy: 0.676200\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     0.6180 Validation Accuracy: 0.686200\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     0.9041 Validation Accuracy: 0.687800\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     0.7653 Validation Accuracy: 0.679400\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     0.7955 Validation Accuracy: 0.668600\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     0.6825 Validation Accuracy: 0.649600\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     0.7110 Validation Accuracy: 0.670600\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     0.9595 Validation Accuracy: 0.650400\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     0.8014 Validation Accuracy: 0.666000\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     0.8093 Validation Accuracy: 0.649200\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     0.5815 Validation Accuracy: 0.673400\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     0.7014 Validation Accuracy: 0.671800\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     1.0080 Validation Accuracy: 0.641000\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     0.7905 Validation Accuracy: 0.692200\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     0.8338 Validation Accuracy: 0.650800\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     0.6476 Validation Accuracy: 0.669200\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     0.7149 Validation Accuracy: 0.671800\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     0.8641 Validation Accuracy: 0.674400\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     0.7762 Validation Accuracy: 0.674600\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     0.7340 Validation Accuracy: 0.681600\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     0.7067 Validation Accuracy: 0.660600\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     0.7389 Validation Accuracy: 0.670000\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     0.9113 Validation Accuracy: 0.665800\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     0.7568 Validation Accuracy: 0.660000\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     0.7534 Validation Accuracy: 0.676600\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     0.6889 Validation Accuracy: 0.664200\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     0.6440 Validation Accuracy: 0.681000\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     0.8738 Validation Accuracy: 0.672800\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     0.7681 Validation Accuracy: 0.688600\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     0.7735 Validation Accuracy: 0.676200\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     0.6970 Validation Accuracy: 0.662400\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     0.6575 Validation Accuracy: 0.678400\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     0.9324 Validation Accuracy: 0.626600\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     0.8258 Validation Accuracy: 0.672400\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     0.7572 Validation Accuracy: 0.659800\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     0.7663 Validation Accuracy: 0.653800\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     0.7171 Validation Accuracy: 0.687600\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     0.7624 Validation Accuracy: 0.682200\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     0.7721 Validation Accuracy: 0.678000\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     0.7878 Validation Accuracy: 0.669800\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     0.6975 Validation Accuracy: 0.665800\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     0.6927 Validation Accuracy: 0.670200\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     0.8621 Validation Accuracy: 0.676600\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     0.7725 Validation Accuracy: 0.669000\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     0.7958 Validation Accuracy: 0.672000\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     0.6545 Validation Accuracy: 0.683200\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     0.7229 Validation Accuracy: 0.680400\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     0.8775 Validation Accuracy: 0.683000\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     0.7653 Validation Accuracy: 0.701200\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     1.0494 Validation Accuracy: 0.622400\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     0.7419 Validation Accuracy: 0.669400\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     0.7528 Validation Accuracy: 0.663000\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     0.9767 Validation Accuracy: 0.642400\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     0.7834 Validation Accuracy: 0.679600\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     0.8098 Validation Accuracy: 0.655400\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     0.6954 Validation Accuracy: 0.680200\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     0.7378 Validation Accuracy: 0.665600\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     0.8474 Validation Accuracy: 0.681800\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     0.7663 Validation Accuracy: 0.693000\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     0.7098 Validation Accuracy: 0.665200\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     0.7135 Validation Accuracy: 0.658600\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     0.7032 Validation Accuracy: 0.674200\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     0.9098 Validation Accuracy: 0.673600\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     0.7593 Validation Accuracy: 0.691800\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     0.8076 Validation Accuracy: 0.668200\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     0.6923 Validation Accuracy: 0.671400\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     0.6590 Validation Accuracy: 0.674800\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     0.8799 Validation Accuracy: 0.680200\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     0.8404 Validation Accuracy: 0.664800\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     0.8699 Validation Accuracy: 0.641800\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     0.6807 Validation Accuracy: 0.679200\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     0.8232 Validation Accuracy: 0.646200\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     0.8617 Validation Accuracy: 0.683000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     0.9018 Validation Accuracy: 0.643200\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     0.7631 Validation Accuracy: 0.679400\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     0.6746 Validation Accuracy: 0.684000\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     0.7480 Validation Accuracy: 0.664000\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     0.8615 Validation Accuracy: 0.682800\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     0.7747 Validation Accuracy: 0.677600\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     0.9334 Validation Accuracy: 0.667000\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     0.7448 Validation Accuracy: 0.659000\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     0.7023 Validation Accuracy: 0.671200\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     0.8673 Validation Accuracy: 0.670800\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     0.7973 Validation Accuracy: 0.692600\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     0.9008 Validation Accuracy: 0.655800\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     0.9713 Validation Accuracy: 0.593200\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     0.6269 Validation Accuracy: 0.681600\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     0.9089 Validation Accuracy: 0.659600\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     0.7087 Validation Accuracy: 0.688400\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     0.7342 Validation Accuracy: 0.687400\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     0.6788 Validation Accuracy: 0.678600\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     0.6228 Validation Accuracy: 0.692000\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     0.9260 Validation Accuracy: 0.671200\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     0.7562 Validation Accuracy: 0.677600\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     0.8769 Validation Accuracy: 0.651800\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     0.6656 Validation Accuracy: 0.681600\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     0.6153 Validation Accuracy: 0.693800\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     0.8978 Validation Accuracy: 0.678400\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     0.7460 Validation Accuracy: 0.685600\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     0.9226 Validation Accuracy: 0.674600\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     0.6656 Validation Accuracy: 0.670200\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     0.6053 Validation Accuracy: 0.688800\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     0.8108 Validation Accuracy: 0.689400\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     0.7946 Validation Accuracy: 0.673600\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     0.8128 Validation Accuracy: 0.673200\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     0.6124 Validation Accuracy: 0.681400\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     0.6077 Validation Accuracy: 0.691400\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     0.7497 Validation Accuracy: 0.693000\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     0.7695 Validation Accuracy: 0.690600\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     0.8813 Validation Accuracy: 0.669400\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     0.6762 Validation Accuracy: 0.685200\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     0.7210 Validation Accuracy: 0.675000\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     0.7782 Validation Accuracy: 0.700800\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     0.8691 Validation Accuracy: 0.641600\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     0.8383 Validation Accuracy: 0.663600\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     0.6754 Validation Accuracy: 0.663800\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     0.7548 Validation Accuracy: 0.679800\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     0.9213 Validation Accuracy: 0.659400\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     0.7310 Validation Accuracy: 0.684000\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     0.8798 Validation Accuracy: 0.669000\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     0.6991 Validation Accuracy: 0.665000\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     0.7592 Validation Accuracy: 0.660400\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     0.9747 Validation Accuracy: 0.634800\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     0.7729 Validation Accuracy: 0.673400\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     0.7652 Validation Accuracy: 0.665000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     0.6187 Validation Accuracy: 0.676800\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     0.7077 Validation Accuracy: 0.677400\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     0.9070 Validation Accuracy: 0.656800\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     0.7884 Validation Accuracy: 0.662800\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     0.8618 Validation Accuracy: 0.649800\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     0.6935 Validation Accuracy: 0.654800\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     0.7729 Validation Accuracy: 0.643400\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     0.8394 Validation Accuracy: 0.673400\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     0.7255 Validation Accuracy: 0.674600\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     0.8064 Validation Accuracy: 0.648400\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     0.7133 Validation Accuracy: 0.650000\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     0.7146 Validation Accuracy: 0.664800\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     0.9780 Validation Accuracy: 0.661000\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     0.7335 Validation Accuracy: 0.695800\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     0.9749 Validation Accuracy: 0.660200\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     0.6696 Validation Accuracy: 0.666400\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     0.6973 Validation Accuracy: 0.677600\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     0.8492 Validation Accuracy: 0.675600\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     0.7252 Validation Accuracy: 0.697600\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     0.8269 Validation Accuracy: 0.662600\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     0.6795 Validation Accuracy: 0.678200\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     0.6690 Validation Accuracy: 0.679200\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     0.7812 Validation Accuracy: 0.699600\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     0.6934 Validation Accuracy: 0.691600\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     0.9082 Validation Accuracy: 0.674000\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     0.6398 Validation Accuracy: 0.687000\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     0.7000 Validation Accuracy: 0.668400\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     0.8992 Validation Accuracy: 0.672400\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     0.8178 Validation Accuracy: 0.675400\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     0.7985 Validation Accuracy: 0.681000\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     0.6625 Validation Accuracy: 0.676200\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     0.6787 Validation Accuracy: 0.682600\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     0.8564 Validation Accuracy: 0.678000\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     0.7671 Validation Accuracy: 0.692000\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     0.8254 Validation Accuracy: 0.669000\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     0.5960 Validation Accuracy: 0.676800\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     0.7003 Validation Accuracy: 0.680400\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     0.8880 Validation Accuracy: 0.686800\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     0.7362 Validation Accuracy: 0.686600\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     0.8582 Validation Accuracy: 0.668400\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     0.6686 Validation Accuracy: 0.674200\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     0.7074 Validation Accuracy: 0.681200\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     0.9397 Validation Accuracy: 0.685200\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     0.7003 Validation Accuracy: 0.682800\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     0.7380 Validation Accuracy: 0.678200\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     0.8181 Validation Accuracy: 0.640600\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     0.6105 Validation Accuracy: 0.688400\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     0.8035 Validation Accuracy: 0.680200\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     0.7385 Validation Accuracy: 0.693200\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     0.8672 Validation Accuracy: 0.670200\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     0.6870 Validation Accuracy: 0.677000\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     0.7148 Validation Accuracy: 0.666800\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     0.7697 Validation Accuracy: 0.674600\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     0.7679 Validation Accuracy: 0.675600\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     0.7499 Validation Accuracy: 0.680000\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     0.6100 Validation Accuracy: 0.690200\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     0.6525 Validation Accuracy: 0.679800\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     0.7325 Validation Accuracy: 0.694200\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     0.7941 Validation Accuracy: 0.678800\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     0.8710 Validation Accuracy: 0.671800\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     0.7720 Validation Accuracy: 0.657200\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     0.6151 Validation Accuracy: 0.668600\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     0.9852 Validation Accuracy: 0.646400\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     0.7715 Validation Accuracy: 0.663800\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     0.7546 Validation Accuracy: 0.686200\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     0.5907 Validation Accuracy: 0.688000\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     0.7214 Validation Accuracy: 0.677200\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     0.8392 Validation Accuracy: 0.669400\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     0.7205 Validation Accuracy: 0.676600\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     0.8222 Validation Accuracy: 0.677600\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     0.5883 Validation Accuracy: 0.674200\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     0.6933 Validation Accuracy: 0.666000\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     0.9526 Validation Accuracy: 0.673000\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     0.7480 Validation Accuracy: 0.670200\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     0.8149 Validation Accuracy: 0.663400\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     0.6653 Validation Accuracy: 0.662200\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     0.6141 Validation Accuracy: 0.681200\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     0.9623 Validation Accuracy: 0.664600\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     0.7568 Validation Accuracy: 0.690400\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     0.7620 Validation Accuracy: 0.677400\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     0.6516 Validation Accuracy: 0.649600\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     0.6369 Validation Accuracy: 0.682600\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     0.9249 Validation Accuracy: 0.668000\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     0.7863 Validation Accuracy: 0.682600\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     0.8223 Validation Accuracy: 0.670600\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     0.7951 Validation Accuracy: 0.668800\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     0.6264 Validation Accuracy: 0.697800\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     0.9104 Validation Accuracy: 0.667600\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     0.7249 Validation Accuracy: 0.691600\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     0.7307 Validation Accuracy: 0.694400\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     0.6531 Validation Accuracy: 0.663600\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     0.6282 Validation Accuracy: 0.683600\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     0.8146 Validation Accuracy: 0.684800\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     0.7640 Validation Accuracy: 0.687200\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     0.7969 Validation Accuracy: 0.684200\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     0.6689 Validation Accuracy: 0.693200\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     0.6189 Validation Accuracy: 0.688800\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     0.9321 Validation Accuracy: 0.693600\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     0.7030 Validation Accuracy: 0.694400\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     0.7937 Validation Accuracy: 0.692600\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     0.6201 Validation Accuracy: 0.655000\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     0.6364 Validation Accuracy: 0.674800\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     0.9845 Validation Accuracy: 0.671600\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     0.7722 Validation Accuracy: 0.679600\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     0.8642 Validation Accuracy: 0.682800\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     0.6194 Validation Accuracy: 0.687400\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     0.7833 Validation Accuracy: 0.645400\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     0.9279 Validation Accuracy: 0.645600\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     0.7632 Validation Accuracy: 0.671600\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     0.7816 Validation Accuracy: 0.685400\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     0.6474 Validation Accuracy: 0.677400\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     0.6903 Validation Accuracy: 0.669800\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     0.8160 Validation Accuracy: 0.682000\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     0.7263 Validation Accuracy: 0.684200\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     0.8460 Validation Accuracy: 0.683800\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     0.7135 Validation Accuracy: 0.670200\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     0.7496 Validation Accuracy: 0.681200\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     0.8766 Validation Accuracy: 0.677800\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     0.8097 Validation Accuracy: 0.670200\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     0.7664 Validation Accuracy: 0.659800\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     0.7254 Validation Accuracy: 0.664800\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     0.8875 Validation Accuracy: 0.644200\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     0.8515 Validation Accuracy: 0.678800\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     0.7291 Validation Accuracy: 0.677600\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     0.8670 Validation Accuracy: 0.656000\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     0.6635 Validation Accuracy: 0.657400\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     0.6887 Validation Accuracy: 0.687000\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     0.8039 Validation Accuracy: 0.691400\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     0.7586 Validation Accuracy: 0.682000\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     0.8831 Validation Accuracy: 0.663600\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     0.6804 Validation Accuracy: 0.659000\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     0.6193 Validation Accuracy: 0.685000\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     0.8884 Validation Accuracy: 0.665600\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     0.8196 Validation Accuracy: 0.668200\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     0.8122 Validation Accuracy: 0.675200\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     0.7607 Validation Accuracy: 0.648600\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     0.6369 Validation Accuracy: 0.683200\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     0.9768 Validation Accuracy: 0.644000\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     0.8335 Validation Accuracy: 0.667800\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     0.8680 Validation Accuracy: 0.643200\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     0.6305 Validation Accuracy: 0.669000\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     0.6045 Validation Accuracy: 0.705600\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     0.8404 Validation Accuracy: 0.688200\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     0.8434 Validation Accuracy: 0.637400\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     0.8823 Validation Accuracy: 0.688600\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     0.5947 Validation Accuracy: 0.690800\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     0.7563 Validation Accuracy: 0.694600\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     1.0912 Validation Accuracy: 0.615000\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     0.8003 Validation Accuracy: 0.675800\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     0.9255 Validation Accuracy: 0.668800\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     0.5934 Validation Accuracy: 0.683600\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     0.7538 Validation Accuracy: 0.685400\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     0.8707 Validation Accuracy: 0.673000\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     0.7867 Validation Accuracy: 0.693600\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     0.9645 Validation Accuracy: 0.654400\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     0.7879 Validation Accuracy: 0.643400\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     0.7393 Validation Accuracy: 0.686600\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     0.8908 Validation Accuracy: 0.677000\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     0.7654 Validation Accuracy: 0.686800\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     0.8305 Validation Accuracy: 0.663200\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     0.7922 Validation Accuracy: 0.643200\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     0.6396 Validation Accuracy: 0.690000\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     0.8806 Validation Accuracy: 0.667000\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     0.7343 Validation Accuracy: 0.684800\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     0.7196 Validation Accuracy: 0.692000\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     0.6435 Validation Accuracy: 0.679200\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     0.7242 Validation Accuracy: 0.675600\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     0.8185 Validation Accuracy: 0.684200\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     0.7574 Validation Accuracy: 0.672200\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     0.8741 Validation Accuracy: 0.628200\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     0.5936 Validation Accuracy: 0.678400\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     0.8352 Validation Accuracy: 0.657000\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     0.8704 Validation Accuracy: 0.685400\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     0.7187 Validation Accuracy: 0.685800\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     0.7130 Validation Accuracy: 0.682000\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     0.6074 Validation Accuracy: 0.691600\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     1.0287 Validation Accuracy: 0.607400\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     0.7893 Validation Accuracy: 0.685800\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     0.7051 Validation Accuracy: 0.699800\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     0.7298 Validation Accuracy: 0.682400\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     0.6887 Validation Accuracy: 0.661000\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     0.7227 Validation Accuracy: 0.687800\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     0.8317 Validation Accuracy: 0.689000\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     0.7325 Validation Accuracy: 0.690200\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     0.7972 Validation Accuracy: 0.672200\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     0.6104 Validation Accuracy: 0.685600\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     0.7779 Validation Accuracy: 0.678000\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     0.9307 Validation Accuracy: 0.678200\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     0.7262 Validation Accuracy: 0.662400\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     0.7728 Validation Accuracy: 0.658000\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     0.7872 Validation Accuracy: 0.643400\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     0.7217 Validation Accuracy: 0.681200\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     1.1505 Validation Accuracy: 0.565800\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     0.7899 Validation Accuracy: 0.656800\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     0.8603 Validation Accuracy: 0.656000\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     0.6740 Validation Accuracy: 0.671800\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     0.7803 Validation Accuracy: 0.676800\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     0.8384 Validation Accuracy: 0.682400\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     0.7329 Validation Accuracy: 0.685000\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     0.8019 Validation Accuracy: 0.683400\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     0.6603 Validation Accuracy: 0.667600\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     0.7440 Validation Accuracy: 0.681800\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     0.8272 Validation Accuracy: 0.692400\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     0.7987 Validation Accuracy: 0.684200\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     0.7292 Validation Accuracy: 0.691600\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     0.6188 Validation Accuracy: 0.662800\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     0.7263 Validation Accuracy: 0.680600\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     0.8082 Validation Accuracy: 0.683600\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     0.8050 Validation Accuracy: 0.685400\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     0.7934 Validation Accuracy: 0.657400\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     0.6398 Validation Accuracy: 0.657400\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     0.8028 Validation Accuracy: 0.665000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     0.8980 Validation Accuracy: 0.677000\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     0.7490 Validation Accuracy: 0.695200\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     0.8315 Validation Accuracy: 0.661600\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     0.7089 Validation Accuracy: 0.671600\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     0.7888 Validation Accuracy: 0.660400\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     0.8788 Validation Accuracy: 0.684600\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     0.7459 Validation Accuracy: 0.671600\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     1.0003 Validation Accuracy: 0.595800\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     0.6852 Validation Accuracy: 0.667000\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     0.7008 Validation Accuracy: 0.691200\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     0.7390 Validation Accuracy: 0.704600\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     0.8539 Validation Accuracy: 0.676600\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     0.8232 Validation Accuracy: 0.679800\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     0.5874 Validation Accuracy: 0.696400\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     0.6319 Validation Accuracy: 0.688800\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     0.8455 Validation Accuracy: 0.683000\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     0.7750 Validation Accuracy: 0.683400\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     0.8586 Validation Accuracy: 0.678200\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     0.6036 Validation Accuracy: 0.681600\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     0.6270 Validation Accuracy: 0.683000\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     0.9747 Validation Accuracy: 0.655000\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     0.9236 Validation Accuracy: 0.653600\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     0.8519 Validation Accuracy: 0.665600\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     0.5990 Validation Accuracy: 0.679800\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     0.6794 Validation Accuracy: 0.692800\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     0.8982 Validation Accuracy: 0.674800\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     0.8090 Validation Accuracy: 0.689800\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     0.9152 Validation Accuracy: 0.648400\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     0.6063 Validation Accuracy: 0.676000\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     0.7397 Validation Accuracy: 0.681200\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     0.9177 Validation Accuracy: 0.680000\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     0.7956 Validation Accuracy: 0.681200\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     0.8469 Validation Accuracy: 0.683400\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     0.7012 Validation Accuracy: 0.665400\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     0.7043 Validation Accuracy: 0.671600\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     0.9144 Validation Accuracy: 0.661400\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     0.7525 Validation Accuracy: 0.679800\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     0.8032 Validation Accuracy: 0.689800\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     0.6867 Validation Accuracy: 0.674000\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     0.6707 Validation Accuracy: 0.684600\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     0.9332 Validation Accuracy: 0.657800\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     0.7802 Validation Accuracy: 0.670400\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     0.8250 Validation Accuracy: 0.682000\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     0.6119 Validation Accuracy: 0.683400\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     0.7643 Validation Accuracy: 0.657800\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     0.8159 Validation Accuracy: 0.677200\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     0.7429 Validation Accuracy: 0.694600\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     0.8355 Validation Accuracy: 0.656400\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     0.5929 Validation Accuracy: 0.683800\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     0.7169 Validation Accuracy: 0.680600\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     0.8048 Validation Accuracy: 0.699200\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     0.7603 Validation Accuracy: 0.702200\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     0.7623 Validation Accuracy: 0.693200\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     0.6587 Validation Accuracy: 0.677000\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     0.6825 Validation Accuracy: 0.690000\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     0.8573 Validation Accuracy: 0.675400\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     0.7616 Validation Accuracy: 0.692600\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     0.9003 Validation Accuracy: 0.634000\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     0.7220 Validation Accuracy: 0.652000\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     0.7135 Validation Accuracy: 0.673600\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     1.1486 Validation Accuracy: 0.618800\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     0.7124 Validation Accuracy: 0.683400\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     0.7675 Validation Accuracy: 0.673200\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     0.6050 Validation Accuracy: 0.682200\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     0.6494 Validation Accuracy: 0.677200\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     0.7902 Validation Accuracy: 0.694600\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     0.7870 Validation Accuracy: 0.685400\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     0.9388 Validation Accuracy: 0.654800\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     0.6737 Validation Accuracy: 0.675000\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     0.7088 Validation Accuracy: 0.663600\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     0.9123 Validation Accuracy: 0.683200\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     0.6868 Validation Accuracy: 0.688000\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     0.7396 Validation Accuracy: 0.692200\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     0.6427 Validation Accuracy: 0.676400\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     0.5743 Validation Accuracy: 0.700400\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     0.9513 Validation Accuracy: 0.642800\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     0.8122 Validation Accuracy: 0.677400\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     0.9507 Validation Accuracy: 0.633800\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     0.6515 Validation Accuracy: 0.663400\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     0.7123 Validation Accuracy: 0.643400\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     0.9572 Validation Accuracy: 0.648400\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     0.7446 Validation Accuracy: 0.692400\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     0.7780 Validation Accuracy: 0.697400\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     0.7673 Validation Accuracy: 0.603600\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     0.6049 Validation Accuracy: 0.692000\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     0.9012 Validation Accuracy: 0.680800\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     0.7332 Validation Accuracy: 0.689600\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     0.9242 Validation Accuracy: 0.649200\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     0.5999 Validation Accuracy: 0.672000\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     0.6442 Validation Accuracy: 0.684600\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     0.9602 Validation Accuracy: 0.659800\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     0.7484 Validation Accuracy: 0.683200\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     0.8467 Validation Accuracy: 0.658800\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     0.5814 Validation Accuracy: 0.692800\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     0.7793 Validation Accuracy: 0.688800\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     0.8319 Validation Accuracy: 0.693000\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     0.9661 Validation Accuracy: 0.631400\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     0.8036 Validation Accuracy: 0.685400\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     0.5863 Validation Accuracy: 0.666600\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     0.6795 Validation Accuracy: 0.684600\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     0.9680 Validation Accuracy: 0.667200\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     0.7581 Validation Accuracy: 0.691800\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     0.8481 Validation Accuracy: 0.693800\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     0.6879 Validation Accuracy: 0.657400\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     0.6266 Validation Accuracy: 0.696200\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     0.8428 Validation Accuracy: 0.682400\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     0.8292 Validation Accuracy: 0.680800\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     0.8923 Validation Accuracy: 0.683000\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     0.5331 Validation Accuracy: 0.707400\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     0.6180 Validation Accuracy: 0.700600\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     0.8438 Validation Accuracy: 0.693600\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     0.8052 Validation Accuracy: 0.686600\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     0.8606 Validation Accuracy: 0.686200\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     0.5763 Validation Accuracy: 0.674600\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     0.6190 Validation Accuracy: 0.682600\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     0.9059 Validation Accuracy: 0.692400\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     0.7441 Validation Accuracy: 0.695800\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     0.7890 Validation Accuracy: 0.681000\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     0.6120 Validation Accuracy: 0.680400\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     0.6533 Validation Accuracy: 0.693600\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     0.8531 Validation Accuracy: 0.691800\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     0.7902 Validation Accuracy: 0.683600\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     0.8786 Validation Accuracy: 0.685400\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     0.5990 Validation Accuracy: 0.681800\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     0.6971 Validation Accuracy: 0.681800\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     0.8026 Validation Accuracy: 0.687400\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     0.7270 Validation Accuracy: 0.692400\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     0.8131 Validation Accuracy: 0.665200\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     0.6721 Validation Accuracy: 0.668600\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     0.6238 Validation Accuracy: 0.699400\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     0.7703 Validation Accuracy: 0.695800\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     0.7363 Validation Accuracy: 0.695200\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     0.7984 Validation Accuracy: 0.689600\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     0.5613 Validation Accuracy: 0.695800\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     0.6813 Validation Accuracy: 0.682200\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     0.9037 Validation Accuracy: 0.670000\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     0.7339 Validation Accuracy: 0.692000\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     0.7918 Validation Accuracy: 0.674400\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     0.5481 Validation Accuracy: 0.694400\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     0.6250 Validation Accuracy: 0.685800\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     0.9496 Validation Accuracy: 0.647600\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     0.7619 Validation Accuracy: 0.694000\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     0.8735 Validation Accuracy: 0.675800\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     0.5391 Validation Accuracy: 0.691600\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     0.6934 Validation Accuracy: 0.691000\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     0.8547 Validation Accuracy: 0.692400\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     0.7618 Validation Accuracy: 0.692800\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     0.8268 Validation Accuracy: 0.697400\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     0.5599 Validation Accuracy: 0.689200\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     0.6987 Validation Accuracy: 0.690200\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     0.8026 Validation Accuracy: 0.701800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     0.7718 Validation Accuracy: 0.686600\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     0.7594 Validation Accuracy: 0.673600\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     0.6439 Validation Accuracy: 0.675800\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     0.6826 Validation Accuracy: 0.688000\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     0.8848 Validation Accuracy: 0.671200\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     0.7573 Validation Accuracy: 0.675400\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     0.8675 Validation Accuracy: 0.660400\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     0.7810 Validation Accuracy: 0.640200\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     0.7595 Validation Accuracy: 0.686400\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     0.8950 Validation Accuracy: 0.668400\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     0.7560 Validation Accuracy: 0.678000\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     0.9903 Validation Accuracy: 0.658400\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     0.6562 Validation Accuracy: 0.661600\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     0.7316 Validation Accuracy: 0.675400\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     0.7566 Validation Accuracy: 0.692600\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     0.7496 Validation Accuracy: 0.692000\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     0.8445 Validation Accuracy: 0.688400\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     0.8527 Validation Accuracy: 0.656400\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     0.6692 Validation Accuracy: 0.683600\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     0.9438 Validation Accuracy: 0.654000\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     0.7827 Validation Accuracy: 0.687400\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     0.8291 Validation Accuracy: 0.630800\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     0.6452 Validation Accuracy: 0.671200\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     0.6815 Validation Accuracy: 0.679800\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     0.7796 Validation Accuracy: 0.686600\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     0.7421 Validation Accuracy: 0.687200\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     0.7837 Validation Accuracy: 0.684800\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     0.6581 Validation Accuracy: 0.658600\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     0.6782 Validation Accuracy: 0.690800\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     1.0013 Validation Accuracy: 0.656200\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     0.7501 Validation Accuracy: 0.670600\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     0.7318 Validation Accuracy: 0.677600\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     0.6139 Validation Accuracy: 0.686600\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     0.6724 Validation Accuracy: 0.692400\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     0.9571 Validation Accuracy: 0.660000\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     0.8107 Validation Accuracy: 0.685000\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     0.8832 Validation Accuracy: 0.656200\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     0.6797 Validation Accuracy: 0.684000\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     0.7889 Validation Accuracy: 0.686000\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     0.9396 Validation Accuracy: 0.666400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     0.8161 Validation Accuracy: 0.646800\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     0.8382 Validation Accuracy: 0.686200\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     0.6323 Validation Accuracy: 0.686400\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     0.7290 Validation Accuracy: 0.686400\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     0.7821 Validation Accuracy: 0.677600\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     0.7464 Validation Accuracy: 0.664400\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     0.7892 Validation Accuracy: 0.681400\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     0.6351 Validation Accuracy: 0.679200\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     0.6930 Validation Accuracy: 0.675000\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     0.8426 Validation Accuracy: 0.679000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     0.7419 Validation Accuracy: 0.673000\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     0.8056 Validation Accuracy: 0.665400\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     0.6453 Validation Accuracy: 0.682800\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     0.6309 Validation Accuracy: 0.682200\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     0.9078 Validation Accuracy: 0.649800\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     0.7113 Validation Accuracy: 0.685600\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     0.8894 Validation Accuracy: 0.657600\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     0.7298 Validation Accuracy: 0.675400\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     0.7591 Validation Accuracy: 0.673200\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     0.7766 Validation Accuracy: 0.687400\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     0.7007 Validation Accuracy: 0.662800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     0.7649 Validation Accuracy: 0.684400\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     0.6276 Validation Accuracy: 0.688800\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     0.6869 Validation Accuracy: 0.658600\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     0.8527 Validation Accuracy: 0.663200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     0.7662 Validation Accuracy: 0.664600\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     0.9111 Validation Accuracy: 0.684800\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     0.6278 Validation Accuracy: 0.681200\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     0.7424 Validation Accuracy: 0.683600\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     0.8483 Validation Accuracy: 0.687600\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     0.7537 Validation Accuracy: 0.700400\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     0.8285 Validation Accuracy: 0.683200\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     0.7400 Validation Accuracy: 0.621400\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     0.6935 Validation Accuracy: 0.655000\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     1.1372 Validation Accuracy: 0.606000\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     0.9188 Validation Accuracy: 0.632800\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     0.8083 Validation Accuracy: 0.674400\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     0.6630 Validation Accuracy: 0.656200\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     0.6425 Validation Accuracy: 0.682000\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     0.9765 Validation Accuracy: 0.647000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     0.7305 Validation Accuracy: 0.694000\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     0.7655 Validation Accuracy: 0.703000\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     0.5937 Validation Accuracy: 0.691400\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     0.6742 Validation Accuracy: 0.685200\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     0.8862 Validation Accuracy: 0.675600\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     0.7483 Validation Accuracy: 0.694600\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     0.7628 Validation Accuracy: 0.685400\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     0.6156 Validation Accuracy: 0.690000\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     0.6505 Validation Accuracy: 0.686600\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     1.0061 Validation Accuracy: 0.650600\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     0.7208 Validation Accuracy: 0.689600\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     0.7851 Validation Accuracy: 0.677800\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     0.6714 Validation Accuracy: 0.684400\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     0.6153 Validation Accuracy: 0.684600\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     0.9497 Validation Accuracy: 0.640000\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     0.8411 Validation Accuracy: 0.663200\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     0.7283 Validation Accuracy: 0.683800\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     0.6811 Validation Accuracy: 0.653600\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     0.6654 Validation Accuracy: 0.684400\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     0.8616 Validation Accuracy: 0.679000\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     0.7413 Validation Accuracy: 0.698000\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     0.7270 Validation Accuracy: 0.678800\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     1.2621 Validation Accuracy: 0.481800\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     0.6868 Validation Accuracy: 0.678200\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     0.8453 Validation Accuracy: 0.672400\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     0.7045 Validation Accuracy: 0.677600\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     0.8301 Validation Accuracy: 0.672400\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     0.6506 Validation Accuracy: 0.680400\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     0.7974 Validation Accuracy: 0.653400\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     0.8803 Validation Accuracy: 0.679400\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     0.7838 Validation Accuracy: 0.683400\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     0.8822 Validation Accuracy: 0.683600\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     0.6243 Validation Accuracy: 0.678800\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     0.9288 Validation Accuracy: 0.637200\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     0.8277 Validation Accuracy: 0.695600\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     0.7741 Validation Accuracy: 0.691800\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     0.6856 Validation Accuracy: 0.686400\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     0.6200 Validation Accuracy: 0.683000\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     0.7169 Validation Accuracy: 0.687400\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     0.9163 Validation Accuracy: 0.680400\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     0.7880 Validation Accuracy: 0.689000\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     0.7280 Validation Accuracy: 0.687000\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     0.7288 Validation Accuracy: 0.641000\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     0.7508 Validation Accuracy: 0.667000\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     0.8376 Validation Accuracy: 0.686000\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     0.7800 Validation Accuracy: 0.678800\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     0.7232 Validation Accuracy: 0.691600\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     0.6061 Validation Accuracy: 0.696600\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     0.7278 Validation Accuracy: 0.698200\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     0.8619 Validation Accuracy: 0.667400\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     0.7429 Validation Accuracy: 0.688000\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     0.7304 Validation Accuracy: 0.678200\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     0.6628 Validation Accuracy: 0.693800\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     0.8256 Validation Accuracy: 0.681600\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     0.8292 Validation Accuracy: 0.684400\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     0.7622 Validation Accuracy: 0.686000\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     0.7436 Validation Accuracy: 0.671200\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     0.5877 Validation Accuracy: 0.685600\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     0.8240 Validation Accuracy: 0.673400\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     0.7392 Validation Accuracy: 0.691400\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     0.8866 Validation Accuracy: 0.634600\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     0.7879 Validation Accuracy: 0.699600\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     0.8718 Validation Accuracy: 0.614600\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     0.7375 Validation Accuracy: 0.686600\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     0.9475 Validation Accuracy: 0.665200\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     0.7352 Validation Accuracy: 0.686400\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     0.8361 Validation Accuracy: 0.661600\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     0.5540 Validation Accuracy: 0.692000\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     0.6910 Validation Accuracy: 0.699200\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     0.8147 Validation Accuracy: 0.688000\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     0.6981 Validation Accuracy: 0.706600\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     0.8012 Validation Accuracy: 0.695200\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     0.7125 Validation Accuracy: 0.671400\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     0.8943 Validation Accuracy: 0.672400\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     0.8869 Validation Accuracy: 0.673400\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     0.8415 Validation Accuracy: 0.652200\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     0.8341 Validation Accuracy: 0.692600\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     0.6080 Validation Accuracy: 0.679400\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     0.6530 Validation Accuracy: 0.684400\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     0.8934 Validation Accuracy: 0.675000\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     0.7394 Validation Accuracy: 0.691800\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     0.8362 Validation Accuracy: 0.693400\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     0.6930 Validation Accuracy: 0.670200\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     0.8237 Validation Accuracy: 0.668000\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     0.8695 Validation Accuracy: 0.686400\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     0.7474 Validation Accuracy: 0.677600\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     0.7394 Validation Accuracy: 0.701200\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     0.8365 Validation Accuracy: 0.642400\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     0.7261 Validation Accuracy: 0.695600\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     0.9568 Validation Accuracy: 0.657800\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     0.9960 Validation Accuracy: 0.641200\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     0.7836 Validation Accuracy: 0.699600\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     0.6815 Validation Accuracy: 0.672200\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     0.8512 Validation Accuracy: 0.685400\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     0.7745 Validation Accuracy: 0.687800\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     0.9999 Validation Accuracy: 0.648800\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     0.8348 Validation Accuracy: 0.687200\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     0.6562 Validation Accuracy: 0.694400\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     0.8057 Validation Accuracy: 0.678000\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     0.7366 Validation Accuracy: 0.692200\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     0.9079 Validation Accuracy: 0.644200\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     0.7889 Validation Accuracy: 0.677200\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     0.7534 Validation Accuracy: 0.662800\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     0.6563 Validation Accuracy: 0.695000\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     0.7563 Validation Accuracy: 0.699000\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     0.7769 Validation Accuracy: 0.680000\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     0.8691 Validation Accuracy: 0.653400\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     0.7545 Validation Accuracy: 0.650200\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     0.7903 Validation Accuracy: 0.670800\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     0.7856 Validation Accuracy: 0.684000\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     0.7344 Validation Accuracy: 0.682400\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     0.8353 Validation Accuracy: 0.691200\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     0.6757 Validation Accuracy: 0.690800\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     0.6578 Validation Accuracy: 0.700200\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     0.8825 Validation Accuracy: 0.666000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     0.8054 Validation Accuracy: 0.693400\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     0.8695 Validation Accuracy: 0.687400\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     0.7135 Validation Accuracy: 0.653800\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     0.6851 Validation Accuracy: 0.685000\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     0.8404 Validation Accuracy: 0.683400\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     0.6934 Validation Accuracy: 0.694000\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     0.7814 Validation Accuracy: 0.666000\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     0.6367 Validation Accuracy: 0.665200\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     0.6326 Validation Accuracy: 0.694600\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     0.8237 Validation Accuracy: 0.672400\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     0.7854 Validation Accuracy: 0.681600\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     0.9344 Validation Accuracy: 0.693200\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     0.7223 Validation Accuracy: 0.662000\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     0.6891 Validation Accuracy: 0.681400\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     0.7935 Validation Accuracy: 0.684200\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     0.7127 Validation Accuracy: 0.698800\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     0.7975 Validation Accuracy: 0.689000\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     0.7138 Validation Accuracy: 0.654200\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     0.7129 Validation Accuracy: 0.665400\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     0.7311 Validation Accuracy: 0.694600\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     0.7564 Validation Accuracy: 0.708200\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     0.7404 Validation Accuracy: 0.677200\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     0.7582 Validation Accuracy: 0.651000\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     0.7216 Validation Accuracy: 0.658000\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     0.7511 Validation Accuracy: 0.698400\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     0.7826 Validation Accuracy: 0.699400\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     0.8621 Validation Accuracy: 0.666600\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     0.5846 Validation Accuracy: 0.701000\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     0.6780 Validation Accuracy: 0.682400\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     0.9328 Validation Accuracy: 0.647600\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     0.7063 Validation Accuracy: 0.694000\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     0.7811 Validation Accuracy: 0.686400\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     0.6364 Validation Accuracy: 0.688800\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     0.6280 Validation Accuracy: 0.694200\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     0.7831 Validation Accuracy: 0.693800\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     0.7283 Validation Accuracy: 0.706200\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     0.8113 Validation Accuracy: 0.683800\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     0.5938 Validation Accuracy: 0.681800\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     0.6649 Validation Accuracy: 0.694800\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     0.7741 Validation Accuracy: 0.699000\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     0.7505 Validation Accuracy: 0.670000\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     0.7905 Validation Accuracy: 0.690000\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     0.8089 Validation Accuracy: 0.643400\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     0.6027 Validation Accuracy: 0.688000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     0.8676 Validation Accuracy: 0.678600\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     0.7284 Validation Accuracy: 0.678400\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     0.7309 Validation Accuracy: 0.692400\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     0.5978 Validation Accuracy: 0.683400\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     0.6766 Validation Accuracy: 0.692800\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     0.7783 Validation Accuracy: 0.672400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     0.7143 Validation Accuracy: 0.687200\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     0.7269 Validation Accuracy: 0.688000\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     0.6107 Validation Accuracy: 0.678000\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     0.6752 Validation Accuracy: 0.681400\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     1.3222 Validation Accuracy: 0.556400\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     0.7350 Validation Accuracy: 0.690400\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     0.8383 Validation Accuracy: 0.676600\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     0.5549 Validation Accuracy: 0.693000\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     0.5717 Validation Accuracy: 0.697400\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     0.8259 Validation Accuracy: 0.691000\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     0.8043 Validation Accuracy: 0.690000\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     0.8401 Validation Accuracy: 0.684400\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     0.8815 Validation Accuracy: 0.658000\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     0.5995 Validation Accuracy: 0.708400\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     0.9201 Validation Accuracy: 0.666200\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     0.7222 Validation Accuracy: 0.689800\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     0.8633 Validation Accuracy: 0.654800\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     0.6119 Validation Accuracy: 0.687400\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     0.8478 Validation Accuracy: 0.666600\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     0.9340 Validation Accuracy: 0.682600\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     0.6893 Validation Accuracy: 0.692200\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     0.8544 Validation Accuracy: 0.676600\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     0.6279 Validation Accuracy: 0.679400\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     0.7496 Validation Accuracy: 0.669200\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     0.7607 Validation Accuracy: 0.693800\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     0.6900 Validation Accuracy: 0.680400\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     0.8734 Validation Accuracy: 0.684800\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     0.6057 Validation Accuracy: 0.681200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     0.8190 Validation Accuracy: 0.663400\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     0.8428 Validation Accuracy: 0.691800\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     0.8738 Validation Accuracy: 0.671600\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     1.0281 Validation Accuracy: 0.640200\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     0.6379 Validation Accuracy: 0.673400\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     0.7019 Validation Accuracy: 0.689000\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     0.8029 Validation Accuracy: 0.693200\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     0.6938 Validation Accuracy: 0.697000\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     0.7702 Validation Accuracy: 0.667600\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     0.6615 Validation Accuracy: 0.660000\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     0.6812 Validation Accuracy: 0.679400\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     0.7259 Validation Accuracy: 0.700200\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     0.6969 Validation Accuracy: 0.692600\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     0.9479 Validation Accuracy: 0.664000\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     0.5552 Validation Accuracy: 0.695600\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     0.5747 Validation Accuracy: 0.696400\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     0.8333 Validation Accuracy: 0.689200\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     0.7162 Validation Accuracy: 0.706600\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     0.8330 Validation Accuracy: 0.684400\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     0.5947 Validation Accuracy: 0.692000\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     0.6420 Validation Accuracy: 0.687000\n",
      "Epoch 387, CIFAR-10 Batch 5:  "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
